import openai
from openai import OpenAI, AsyncOpenAI
from typing import Dict, List, Any, AsyncGenerator, Optional
from fastapi import HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
import json
import os
from datetime import datetime

from backend.core.config import settings
from backend.schemas.chat import Message, ChatRequest, ChatCompletionResponse
from backend.utils.logging import api_logger
from backend.crud.chat import create_chat, get_chat, add_message, get_chat_messages, update_chat_agent
from backend.crud.agent import agent as agent_crud
from backend.services.memory import memory_service
from backend.services.tools import tools_service
from backend.config.tools_config import AVAILABLE_TOOLS, get_tools_by_provider, get_tool_by_name
from backend.config.tools_manager import tools_manager

# è·å–é…ç½®å¹¶è¿›è¡Œè°ƒæ•´
api_key = settings.OPENAI_API_KEY
base_url = settings.OPENAI_BASE_URL
model = settings.OPENAI_MODEL

# ç¡®ä¿base_urlä»¥/v1ç»“å°¾
if base_url and not base_url.endswith('/v1'):
    base_url = base_url.rstrip() + '/v1'
    api_logger.info(f"ä¿®æ­£åçš„BASE URL: {base_url}")

# æ‰“å°OpenAIé…ç½®ä¿¡æ¯
api_logger.info(f"OpenAIé…ç½® - API KEY: {api_key[:5]}*****, BASE URL: {base_url}, æ¨¡å‹: {model}")

# é…ç½®OpenAIå®¢æˆ·ç«¯
client = OpenAI(
    api_key=api_key,
    base_url=base_url
)

# é…ç½®å¼‚æ­¥OpenAIå®¢æˆ·ç«¯
async_client = AsyncOpenAI(
    api_key=api_key,
    base_url=base_url
)

# æ‰“å°å®¢æˆ·ç«¯ä¿¡æ¯
api_logger.info(f"OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ - åŒæ­¥å®¢æˆ·ç«¯: {client.base_url}, å¼‚æ­¥å®¢æˆ·ç«¯: {async_client.base_url}")


# è·å–Agenté…ç½®çš„å·¥å…·åˆ—è¡¨
def get_agent_tools(agent):
    """æ ¹æ®Agentçš„é…ç½®è¿”å›å¯ç”¨å·¥å…·åˆ—è¡¨"""
    if not agent or not agent.tools_enabled:
        return []
    
    # ä½¿ç”¨å·¥å…·ç®¡ç†å™¨è·å–å·¥å…·åˆ—è¡¨
    tools = tools_manager.get_agent_tools(agent.tools_enabled)
    
    api_logger.info(f"ä¸ºAgent {agent.name} é…ç½®äº† {len(tools)} ä¸ªå·¥å…·")
    return tools


# å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚
async def handle_tool_calls(tool_calls, agent, db: Optional[AsyncSession] = None, conversation_id: Optional[int] = None):
    """å¤„ç†å·¥å…·è°ƒç”¨è¯·æ±‚å¹¶è¿”å›ç»“æœ"""
    results = []
    tool_calls_data = []  # ç”¨äºä¿å­˜åˆ°æ•°æ®åº“çš„å·¥å…·è°ƒç”¨ä¿¡æ¯
    
    for tool_call in tool_calls:
        tool_call_id = tool_call.id
        function_name = tool_call.function.name
        function_args = json.loads(tool_call.function.arguments)
        
        api_logger.info(f"å¤„ç†å·¥å…·è°ƒç”¨: {function_name}, å‚æ•°: {function_args}")
        
        # åˆå§‹åŒ–å·¥å…·è°ƒç”¨æ•°æ®
        tool_call_data = {
            "id": tool_call_id,
            "name": function_name,
            "arguments": function_args,
            "status": "preparing",
            "result": None,
            "error": None,
            "started_at": datetime.now().isoformat()
        }
        tool_calls_data.append(tool_call_data)
        
        # ä½¿ç”¨å·¥å…·ç®¡ç†å™¨è·å–APIå¯†é’¥
        api_key = None
        if agent and agent.tools_enabled:
            api_key = tools_manager.get_tool_api_key(function_name, agent.tools_enabled)
        
        try:
            # æ›´æ–°çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
            tool_call_data["status"] = "executing"
            
            # æ ¹æ®å‡½æ•°åæ‰§è¡Œç›¸åº”çš„å·¥å…·
            tool_result = None
            if function_name == "tavily_search":
                tool_result = tools_service.execute_tool(
                    tool_name="tavily",
                    action="search",
                    params={
                        "query": function_args.get("query"),
                        "max_results": function_args.get("max_results", 10)
                    },
                    config={"api_key": api_key} if api_key else None
                )
                
            elif function_name == "tavily_extract":
                tool_result = tools_service.execute_tool(
                    tool_name="tavily",
                    action="extract",
                    params={
                        "urls": function_args.get("urls"),
                        "include_images": function_args.get("include_images", False)
                    },
                    config={"api_key": api_key} if api_key else None
                )
            
            elif function_name == "serper_search":
                tool_result = tools_service.execute_tool(
                    tool_name="serper",
                    action="search",
                    params={
                        "query": function_args.get("query"),
                        "max_results": function_args.get("max_results", 10),
                        "gl": function_args.get("gl", "cn"),
                        "hl": function_args.get("hl", "zh-cn")
                    },
                    config={"api_key": api_key} if api_key else None
                )
            
            elif function_name == "serper_news":
                tool_result = tools_service.execute_tool(
                    tool_name="serper",
                    action="news_search",
                    params={
                        "query": function_args.get("query"),
                        "max_results": function_args.get("max_results", 10),
                        "gl": function_args.get("gl", "cn"),
                        "hl": function_args.get("hl", "zh-cn")
                    },
                    config={"api_key": api_key} if api_key else None
                )
            
            elif function_name == "serper_scrape":
                tool_result = tools_service.execute_tool(
                    tool_name="serper",
                    action="scrape_url",
                    params={
                        "url": function_args.get("url"),
                        "include_markdown": function_args.get("include_markdown", True)
                    },
                    config={"api_key": api_key} if api_key else None
                )
            
            # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
            tool_call_data["status"] = "completed"
            tool_call_data["result"] = tool_result
            tool_call_data["completed_at"] = datetime.now().isoformat()
            
            results.append({
                "tool_call_id": tool_call_id,
                "role": "tool",
                "name": function_name,
                "content": json.dumps(tool_result, ensure_ascii=False)
            })
            
        except Exception as e:
            api_logger.error(f"å·¥å…·è°ƒç”¨å¤±è´¥: {function_name}, é”™è¯¯: {str(e)}")
            
            # æ›´æ–°çŠ¶æ€ä¸ºé”™è¯¯
            tool_call_data["status"] = "error"
            tool_call_data["error"] = str(e)
            tool_call_data["completed_at"] = datetime.now().isoformat()
            
            # è¿”å›é”™è¯¯ç»“æœ
            results.append({
                "tool_call_id": tool_call_id,
                "role": "tool",
                "name": function_name,
                "content": json.dumps({"error": str(e)}, ensure_ascii=False)
            })
    
    api_logger.info(f"å®Œæˆ {len(results)} ä¸ªå·¥å…·è°ƒç”¨")
    return results, tool_calls_data


async def generate_chat_response(
    chat_request: ChatRequest,
    db: Optional[AsyncSession] = None,
    user_id: Optional[int] = None
) -> ChatCompletionResponse:
    """
    è°ƒç”¨OpenAI APIç”Ÿæˆå¯¹è¯å“åº”ï¼Œå¹¶ä¿å­˜å¯¹è¯è®°å½•
    """
    try:
        api_logger.info(f"å¼€å§‹è°ƒç”¨OpenAI API, æ¨¡å‹: {model}, APIåœ°å€: {base_url}")
        
        # è·å–æˆ–ç¡®è®¤èŠå¤©ä¼šè¯ID
        conversation_id = chat_request.conversation_id
        
        # è·å–Agentä¿¡æ¯
        agent_id = chat_request.agent_id
        current_agent = None
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        use_model = model
        max_tokens = 4000
        temperature = 0.7
        top_p = 1.0
        
        if agent_id and db:
            # è·å–Agentä¿¡æ¯
            current_agent = await agent_crud.get_agent_for_user(db, agent_id=agent_id, user_id=user_id)
            if not current_agent:
                api_logger.warning(f"Agentä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®: agent_id={agent_id}, user_id={user_id}")
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="Agentä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                )
            api_logger.info(f"ä½¿ç”¨Agent: {current_agent.name}, ID={current_agent.id}")
        
        # ä¼šè¯åˆ›å»ºæˆ–éªŒè¯
        if db and user_id:
            # è·å–æˆ–åˆ›å»ºèŠå¤©ä¼šè¯
            if not conversation_id:
                # åˆ›å»ºæ–°çš„èŠå¤©ä¼šè¯
                if hasattr(chat_request, "note_id") and chat_request.note_id:
                    # æŸ¥è¯¢ç¬”è®°ä¿¡æ¯ï¼Œè·å–æ ‡é¢˜
                    from backend.models.note import Note
                    from sqlalchemy import select
                    
                    # æŸ¥è¯¢ç¬”è®°æ˜¯å¦å­˜åœ¨
                    note_stmt = select(Note).where(
                        Note.id == chat_request.note_id,
                        Note.user_id == user_id,
                        Note.is_deleted == False
                    )
                    note_result = await db.execute(note_stmt)
                    note = note_result.scalar_one_or_none()
                    
                    # åˆ›å»ºèŠå¤©å¯¹è±¡å¹¶ä¼ é€’note_id
                    from backend.schemas.chat import ChatCreate
                    
                    # ä¸ä½¿ç”¨ç¬”è®°æ ‡é¢˜ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜
                    chat_data = ChatCreate(title="æ–°å¯¹è¯")
                    api_logger.info(f"ä»ç¬”è®°åˆ›å»ºæ–°ä¼šè¯ï¼Œä½¿ç”¨é»˜è®¤æ ‡é¢˜'æ–°å¯¹è¯'ï¼Œåç»­å°†è‡ªåŠ¨ç”Ÿæˆ")
                    
                    chat = await create_chat(db, user_id, chat_data=chat_data, agent_id=agent_id)
                    
                    # å¦‚æœåˆ›å»ºæˆåŠŸï¼Œå°†ä¼šè¯IDå…³è”åˆ°ç¬”è®°
                    if chat and chat_request.note_id and note:
                        note.session_id = chat.id
                        await db.commit()
                        api_logger.info(f"ç¬”è®°ID {chat_request.note_id} å·²å…³è”åˆ°ä¼šè¯ID {chat.id}")
                else:
                    # å¸¸è§„åˆ›å»ºä¼šè¯
                    chat = await create_chat(db, user_id, agent_id=agent_id)
                    
                conversation_id = chat.id
                api_logger.info(f"åˆ›å»ºæ–°èŠå¤©ä¼šè¯: conversation_id={conversation_id}, user_id={user_id}, agent_id={agent_id}")
            else:
                # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
                chat = await get_chat(db, conversation_id)
                if not chat or chat.user_id != user_id:
                    raise HTTPException(
                        status_code=status.HTTP_404_NOT_FOUND,
                        detail="èŠå¤©ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                    )
                
                # å¦‚æœå½“å‰ä¼šè¯æ²¡æœ‰å…³è”Agentï¼Œä½†è¯·æ±‚ä¸­æœ‰Agentï¼Œåˆ™æ›´æ–°ä¼šè¯
                if agent_id and not chat.agent_id:
                    await update_chat_agent(db, conversation_id=conversation_id, agent_id=agent_id)
                    api_logger.info(f"æ›´æ–°ä¼šè¯çš„Agent: conversation_id={conversation_id}, agent_id={agent_id}")
                
                # å¦‚æœå½“å‰ä¼šè¯å·²å…³è”Agentï¼Œä½¿ç”¨è¯¥Agentçš„ä¿¡æ¯
                elif chat.agent_id and not agent_id:
                    agent_id = chat.agent_id
                    current_agent = await agent_crud.get_agent_by_id(db, agent_id=agent_id)
                    if current_agent:
                        api_logger.info(f"ä»ä¼šè¯åŠ è½½Agent: {current_agent.name}, ID={current_agent.id}")
        
        # è·å–ç”¨æˆ·å‘é€çš„å†…å®¹
        user_content = chat_request.content
        
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­
        memory_service.add_user_message(conversation_id, user_content, user_id)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
        if db and user_id and conversation_id:
            await add_message(
                db=db,
                conversation_id=conversation_id,
                role="user",
                content=user_content
            )
        
        # ä»è®°å¿†æœåŠ¡è·å–å®Œæ•´çš„æ¶ˆæ¯è®°å½•
        messages = memory_service.get_messages(conversation_id)
        
        # æ·»åŠ Agentçš„ç³»ç»Ÿæç¤ºè¯
        if current_agent and current_agent.system_prompt:
            # åœ¨æ¶ˆæ¯å¼€å¤´æ·»åŠ ç³»ç»Ÿæç¤º
            system_prompt = {"role": "system", "content": current_agent.system_prompt}
            messages.insert(0, system_prompt)
            api_logger.info(f"æ·»åŠ Agentç³»ç»Ÿæç¤ºè¯: {current_agent.system_prompt[:30]}...")
        
        api_logger.debug(f"è¯·æ±‚æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False)}")
        
        # å¦‚æœæœ‰Agentï¼Œä½¿ç”¨Agentçš„è®¾ç½®
        if current_agent:
            # å…ˆå¤‡ä»½ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼Œä»¥é˜²æŒ‡å®šæ¨¡å‹ä¸å¯ç”¨
            agent_model = current_agent.model
            use_model = agent_model if agent_model else model
            
            # å¦‚æœAgentæœ‰æ¨¡å‹è®¾ç½®ï¼Œä½¿ç”¨Agentçš„æ¨¡å‹è®¾ç½®
            if current_agent.model_settings:
                model_settings = current_agent.model_settings
                # ç¡®ä¿model_settingsæ˜¯å­—å…¸
                if not isinstance(model_settings, dict) and hasattr(model_settings, "dict"):
                    model_settings = model_settings.dict()
                elif not isinstance(model_settings, dict):
                    model_settings = {}
                
                if "temperature" in model_settings:
                    temperature = model_settings["temperature"]
                if "top_p" in model_settings:
                    top_p = model_settings["top_p"]
                if "max_tokens" in model_settings:
                    max_tokens = model_settings["max_tokens"]
            
            api_logger.info(f"ä½¿ç”¨Agentæ¨¡å‹è®¾ç½®: model={use_model}, temperature={temperature}, top_p={top_p}, max_tokens={max_tokens}")
        
        # è·å–å·¥å…·é…ç½®
        tools = get_agent_tools(current_agent) if current_agent else []
        has_tools = len(tools) > 0
        api_logger.info(f"å½“å‰èŠå¤©å¯ç”¨å·¥å…·: {has_tools}, å·¥å…·æ•°é‡: {len(tools)}")
        
        # è°ƒç”¨API - å°è¯•ç›´æ¥ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯
        try:
            api_logger.info(f"ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯è°ƒç”¨API - URL: {client.base_url}")
            
            # å‡†å¤‡APIè°ƒç”¨å‚æ•°
            api_params = {
                "model": use_model,
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": temperature,
                "top_p": top_p,
                "stream": False
            }
            
            # å¦‚æœæœ‰å·¥å…·ï¼Œæ·»åŠ å·¥å…·é…ç½®
            if has_tools:
                api_params["tools"] = tools
            
            # è°ƒç”¨API
            response = client.chat.completions.create(**api_params)
            
            api_logger.debug(f"APIåŸå§‹å“åº”ç±»å‹: {type(response)}")
            # è®°å½•åŸå§‹å“åº”å†…å®¹
            api_logger.info(f"APIåŸå§‹å“åº”å†…å®¹: {json.dumps(response.model_dump(), ensure_ascii=False)}")
            
            # æ£€æŸ¥å“åº”ç±»å‹
            if isinstance(response, str):
                api_logger.error(f"APIè¿”å›äº†å­—ç¬¦ä¸²è€Œä¸æ˜¯å¯¹è±¡: {response}")
                raise ValueError(f"APIè¿”å›äº†é”™è¯¯æ ¼å¼: {response}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            assistant_message = response.choices[0].message
            tool_calls = assistant_message.tool_calls if hasattr(assistant_message, 'tool_calls') else None
            
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨
            if tool_calls:
                api_logger.info(f"æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨è¯·æ±‚: {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                
                # å¤„ç†å·¥å…·è°ƒç”¨
                tool_results, tool_calls_data = await handle_tool_calls(tool_calls, current_agent, db, conversation_id)
                
                # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
                messages.append({
                    "role": "assistant",
                    "content": assistant_message.content,
                    "tool_calls": [
                        {
                            "id": tc.id,
                            "type": "function",
                            "function": {
                                "name": tc.function.name,
                                "arguments": tc.function.arguments
                            }
                        } for tc in tool_calls
                    ]
                })
                
                # æ·»åŠ å·¥å…·ç»“æœ
                for tool_result in tool_results:
                    messages.append(tool_result)
                
                api_logger.info(f"ä½¿ç”¨å·¥å…·ç»“æœè°ƒç”¨ç¬¬äºŒæ¬¡API")
                
                # ç¬¬äºŒæ¬¡è°ƒç”¨APIï¼ŒåŒ…å«å·¥å…·ç»“æœ
                second_response = client.chat.completions.create(
                    model=use_model,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    stream=False
                )
                
                # æå–æœ€ç»ˆå“åº”
                token_usage = second_response.usage
                assistant_content = second_response.choices[0].message.content
                
                # å°†æœ€ç»ˆçš„åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­
                memory_service.add_assistant_message(conversation_id, assistant_content, user_id)
                
                # å¦‚æœæä¾›äº†æ•°æ®åº“ä¼šè¯ï¼Œä¿å­˜AIå›å¤ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼‰
                if db and user_id and conversation_id:
                    await add_message(
                        db=db,
                        conversation_id=conversation_id,
                        role="assistant",
                        content=assistant_content,
                        tokens=token_usage.completion_tokens,
                        prompt_tokens=token_usage.prompt_tokens,
                        total_tokens=token_usage.total_tokens,
                        agent_id=agent_id,
                        tool_calls_data=tool_calls_data
                    )
                
                api_logger.info(f"å·¥å…·è°ƒç”¨å®Œæˆï¼Œæœ€ç»ˆå“åº”é•¿åº¦: {len(assistant_content)}")
            else:
                # å¸¸è§„å“åº”å¤„ç†
                token_usage = response.usage
                assistant_content = assistant_message.content
                
                # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­
                memory_service.add_assistant_message(conversation_id, assistant_content, user_id)
                
                # å¦‚æœæä¾›äº†æ•°æ®åº“ä¼šè¯ï¼Œä¿å­˜AIå›å¤
                if db and user_id and conversation_id:
                    await add_message(
                        db=db,
                        conversation_id=conversation_id,
                        role="assistant",
                        content=assistant_content,
                        tokens=token_usage.completion_tokens,
                        prompt_tokens=token_usage.prompt_tokens,
                        total_tokens=token_usage.total_tokens,
                        agent_id=agent_id
                    )
                
                api_logger.info(f"OpenAI APIè°ƒç”¨æˆåŠŸ, ç”Ÿæˆæ–‡æœ¬é•¿åº¦: {len(assistant_content)}")
            
            return ChatCompletionResponse(
                message=Message(
                    content=assistant_content
                ),
                usage={
                    "prompt_tokens": token_usage.prompt_tokens,
                    "completion_tokens": token_usage.completion_tokens,
                    "total_tokens": token_usage.total_tokens
                },
                conversation_id=conversation_id
            )
        except Exception as api_error:
            api_logger.error(f"OpenAI APIè°ƒç”¨å‡ºé”™: {str(api_error)}", exc_info=True)
            
            # å¦‚æœæ˜¯å› ä¸ºæ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹
            if "æ— å¯ç”¨æ¸ é“" in str(api_error) and current_agent and use_model != model:
                api_logger.info(f"å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹ {model} é‡æ–°è¯·æ±‚")
                try:
                    response = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        max_tokens=max_tokens,
                        temperature=temperature,
                        top_p=top_p,
                        stream=False
                    )
                    
                    # æå–å¹¶è¿”å›å“åº”
                    assistant_message = response.choices[0].message
                    token_usage = response.usage
                    assistant_content = assistant_message.content
                    
                    # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­
                    memory_service.add_assistant_message(conversation_id, assistant_content, user_id)
                    
                    api_logger.info(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹ {model} æˆåŠŸ, ç”Ÿæˆæ–‡æœ¬é•¿åº¦: {len(assistant_content)}")
                    
                    # å¦‚æœæä¾›äº†æ•°æ®åº“ä¼šè¯ï¼Œä¿å­˜AIå›å¤
                    if db and user_id and conversation_id:
                        await add_message(
                            db=db,
                            conversation_id=conversation_id,
                            role="assistant",
                            content=assistant_content,
                            tokens=token_usage.completion_tokens,
                            prompt_tokens=token_usage.prompt_tokens,
                            total_tokens=token_usage.total_tokens,
                            agent_id=agent_id
                        )
                    
                    return ChatCompletionResponse(
                        message=Message(
                            content=assistant_content
                        ),
                        usage={
                            "prompt_tokens": token_usage.prompt_tokens,
                            "completion_tokens": token_usage.completion_tokens,
                            "total_tokens": token_usage.total_tokens
                        },
                        conversation_id=conversation_id
                    )
                except Exception as fallback_error:
                    api_logger.error(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹ {model} ä»ç„¶å¤±è´¥: {str(fallback_error)}", exc_info=True)
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å“åº”ï¼Œé¿å…è¿›ä¸€æ­¥çš„é”™è¯¯
            error_message = f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(api_error)}"
            
            if db and user_id and conversation_id:
                await add_message(
                    db=db,
                    conversation_id=conversation_id,
                    role="assistant",
                    content=error_message
                )
            
            return ChatCompletionResponse(
                message=Message(
                    content=error_message
                ),
                usage={
                    "prompt_tokens": len(str(messages)),
                    "completion_tokens": len(error_message),
                    "total_tokens": len(str(messages)) + len(error_message)
                },
                conversation_id=conversation_id
            )
            
    except Exception as e:
        api_logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}", exc_info=True)
        
        # åˆ›å»ºä¸€ä¸ªç®€å•çš„å“åº”ï¼Œé¿å…è¿›ä¸€æ­¥çš„é”™è¯¯
        error_message = f"AIæœåŠ¡å‘ç”Ÿé”™è¯¯: {str(e)}"
        
        if db and user_id and conversation_id:
            try:
                await add_message(
                    db=db,
                    conversation_id=conversation_id,
                    role="assistant",
                    content=error_message
                )
            except Exception as db_error:
                api_logger.error(f"ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“å¤±è´¥: {str(db_error)}")
        
        return ChatCompletionResponse(
            message=Message(
                content=error_message
            ),
            usage={
                "prompt_tokens": 0,
                "completion_tokens": 0,
                "total_tokens": 0
            },
            conversation_id=conversation_id
        )


async def generate_chat_stream(
    chat_request: ChatRequest,
    db: Optional[AsyncSession] = None,
    user_id: Optional[int] = None
) -> AsyncGenerator[str, None]:
    """
    è°ƒç”¨OpenAI APIç”Ÿæˆå¯¹è¯æµå¼å“åº”ï¼Œå¹¶ä¿å­˜å¯¹è¯è®°å½•
    
    è¿”å›çš„æ˜¯ç”Ÿæˆå†…å®¹çš„å¼‚æ­¥ç”Ÿæˆå™¨ã€‚ç¬¬ä¸€ä¸ªå†…å®¹ä¼šé¢å¤–è¿”å›conversation_id
    """
    try:
        api_logger.info(f"å¼€å§‹è°ƒç”¨OpenAIæµå¼API, æ¨¡å‹: {model}, APIåœ°å€: {base_url}")
        
        # è·å–æˆ–ç¡®è®¤èŠå¤©ä¼šè¯ID
        conversation_id = chat_request.conversation_id
        new_session_created = False
        note_id = None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¬”è®°IDéœ€è¦å…³è”
        if hasattr(chat_request, "note_id") and chat_request.note_id:
            note_id = chat_request.note_id
        
        # è·å–Agentä¿¡æ¯
        agent_id = chat_request.agent_id
        current_agent = None
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        use_model = model
        max_tokens = 4000
        temperature = 0.7
        top_p = 1.0
        
        if agent_id and db:
            # è·å–Agentä¿¡æ¯
            current_agent = await agent_crud.get_agent_for_user(db, agent_id=agent_id, user_id=user_id)
            if not current_agent:
                api_logger.warning(f"Agentä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®: agent_id={agent_id}, user_id={user_id}")
                raise HTTPException(
                    status_code=status.HTTP_404_NOT_FOUND,
                    detail="Agentä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                )
            api_logger.info(f"æµå¼å“åº”ä½¿ç”¨Agent: {current_agent.name}, ID={current_agent.id}")
        
        if db and user_id:
            # è·å–æˆ–åˆ›å»ºèŠå¤©ä¼šè¯
            if not conversation_id:
                # åˆ›å»ºæ–°çš„èŠå¤©ä¼šè¯
                if note_id:
                    # æŸ¥è¯¢ç¬”è®°ä¿¡æ¯ï¼Œè·å–æ ‡é¢˜
                    from backend.models.note import Note
                    from sqlalchemy import select
                    
                    # æŸ¥è¯¢ç¬”è®°æ˜¯å¦å­˜åœ¨
                    note_stmt = select(Note).where(
                        Note.id == note_id,
                        Note.user_id == user_id,
                        Note.is_deleted == False
                    )
                    note_result = await db.execute(note_stmt)
                    note = note_result.scalar_one_or_none()
                    
                    # åˆ›å»ºèŠå¤©å¯¹è±¡å¹¶ä¼ é€’note_id
                    from backend.schemas.chat import ChatCreate
                    
                    # ä¸ä½¿ç”¨ç¬”è®°æ ‡é¢˜ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜
                    chat_data = ChatCreate(title="æ–°å¯¹è¯")
                    api_logger.info(f"ä»ç¬”è®°åˆ›å»ºæ–°ä¼šè¯ï¼Œä½¿ç”¨é»˜è®¤æ ‡é¢˜'æ–°å¯¹è¯'ï¼Œåç»­å°†è‡ªåŠ¨ç”Ÿæˆ")
                    
                    chat = await create_chat(db, user_id, chat_data=chat_data, agent_id=agent_id)
                    
                    # å¦‚æœåˆ›å»ºæˆåŠŸï¼Œå°†ä¼šè¯IDå…³è”åˆ°ç¬”è®°
                    if chat and note_id and note:
                        note.session_id = chat.id
                        await db.commit()
                        api_logger.info(f"æµå¼API: ç¬”è®°ID {note_id} å·²å…³è”åˆ°ä¼šè¯ID {chat.id}")
                else:
                    # å¸¸è§„åˆ›å»ºä¼šè¯
                    chat = await create_chat(db, user_id, agent_id=agent_id)
                
                conversation_id = chat.id
                new_session_created = True
                api_logger.info(f"åˆ›å»ºæ–°èŠå¤©ä¼šè¯: conversation_id={conversation_id}, user_id={user_id}, agent_id={agent_id}")
            else:
                # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
                chat = await get_chat(db, conversation_id)
                if not chat or chat.user_id != user_id:
                    raise HTTPException(
                        status_code=status.HTTP_404_NOT_FOUND,
                        detail="èŠå¤©ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                    )
                
                # å¦‚æœå½“å‰ä¼šè¯æ²¡æœ‰å…³è”Agentï¼Œä½†è¯·æ±‚ä¸­æœ‰Agentï¼Œåˆ™æ›´æ–°ä¼šè¯
                if agent_id and not chat.agent_id:
                    await update_chat_agent(db, conversation_id=conversation_id, agent_id=agent_id)
                    api_logger.info(f"æ›´æ–°ä¼šè¯çš„Agent: conversation_id={conversation_id}, agent_id={agent_id}")
                
                # å¦‚æœå½“å‰ä¼šè¯å·²å…³è”Agentï¼Œä½¿ç”¨è¯¥Agentçš„ä¿¡æ¯
                elif chat.agent_id and not agent_id:
                    agent_id = chat.agent_id
                    current_agent = await agent_crud.get_agent_by_id(db, agent_id=agent_id)
                    if current_agent:
                        api_logger.info(f"ä»ä¼šè¯åŠ è½½Agent: {current_agent.name}, ID={current_agent.id}")
                        
                api_logger.info(f"ä½¿ç”¨ç°æœ‰ä¼šè¯: conversation_id={conversation_id}")
        else:
            # å¦‚æœconversation_idå·²ç»å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆAPIå±‚é¢„åˆ›å»ºçš„æƒ…å†µï¼‰
            if conversation_id:
                api_logger.info(f"ä½¿ç”¨APIå±‚é¢„åˆ›å»ºçš„ä¼šè¯: conversation_id={conversation_id}")
            else:
                api_logger.warning("æ²¡æœ‰æ•°æ®åº“è¿æ¥æˆ–ç”¨æˆ·IDï¼Œæ— æ³•åˆ›å»ºæˆ–éªŒè¯ä¼šè¯")
        
        # è·å–ç”¨æˆ·å‘é€çš„å†…å®¹
        user_content = chat_request.content
        
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­
        memory_service.add_user_message(conversation_id, user_content, user_id)
        
        # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“
        if db and user_id and conversation_id:
            await add_message(
                db=db,
                conversation_id=conversation_id,
                role="user",
                content=user_content
            )
        
        # ä»è®°å¿†æœåŠ¡è·å–å®Œæ•´çš„æ¶ˆæ¯è®°å½•
        messages = memory_service.get_messages(conversation_id)
        
        # æ·»åŠ Agentçš„ç³»ç»Ÿæç¤ºè¯
        if current_agent and current_agent.system_prompt:
            # åœ¨æ¶ˆæ¯å¼€å¤´æ·»åŠ ç³»ç»Ÿæç¤º
            system_prompt = {"role": "system", "content": current_agent.system_prompt}
            messages.insert(0, system_prompt)
            api_logger.info(f"æ·»åŠ Agentç³»ç»Ÿæç¤ºè¯: {current_agent.system_prompt[:30]}...")
        
        api_logger.debug(f"æµå¼è¯·æ±‚æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False)}")
        
        # å¦‚æœæœ‰Agentï¼Œä½¿ç”¨Agentçš„è®¾ç½®
        if current_agent:
            # å…ˆå¤‡ä»½ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼Œä»¥é˜²æŒ‡å®šæ¨¡å‹ä¸å¯ç”¨
            agent_model = current_agent.model
            use_model = agent_model if agent_model else model
            
            # å¦‚æœAgentæœ‰æ¨¡å‹è®¾ç½®ï¼Œä½¿ç”¨Agentçš„æ¨¡å‹è®¾ç½®
            if current_agent.model_settings:
                model_settings = current_agent.model_settings
                # ç¡®ä¿model_settingsæ˜¯å­—å…¸
                if not isinstance(model_settings, dict) and hasattr(model_settings, "dict"):
                    model_settings = model_settings.dict()
                elif not isinstance(model_settings, dict):
                    model_settings = {}
                
                if "temperature" in model_settings:
                    temperature = model_settings["temperature"]
                if "top_p" in model_settings:
                    top_p = model_settings["top_p"]
                if "max_tokens" in model_settings:
                    max_tokens = model_settings["max_tokens"]
            
            api_logger.info(f"ä½¿ç”¨Agentæ¨¡å‹è®¾ç½®: model={use_model}, temperature={temperature}, top_p={top_p}, max_tokens={max_tokens}")
        
        # è·å–å·¥å…·é…ç½®
        tools = get_agent_tools(current_agent) if current_agent else []
        has_tools = len(tools) > 0
        api_logger.info(f"æµå¼èŠå¤©å¯ç”¨å·¥å…·: {has_tools}, å·¥å…·æ•°é‡: {len(tools)}")
        
        # è°ƒç”¨æµå¼API
        try:
            api_logger.info(f"å°è¯•åŒæ­¥è°ƒç”¨æµå¼API - URL: {client.base_url}")
            
            # å‡†å¤‡APIè°ƒç”¨å‚æ•°
            api_params = {
                "model": use_model,
                "messages": messages,
                "max_tokens": max_tokens,
                "temperature": temperature,
                "top_p": top_p,
                "stream": True  # å¼€å¯æµå¼å“åº”
            }
            
            # å¦‚æœæœ‰å·¥å…·ï¼Œæ·»åŠ å·¥å…·é…ç½®
            if has_tools:
                api_params["tools"] = tools
                api_logger.info(f"æµå¼å“åº”ä¸­æ·»åŠ å·¥å…·é…ç½®: {len(tools)} ä¸ªå·¥å…·")
            
            # ç›´æ¥ä½¿ç”¨åŒæ­¥å®¢æˆ·ç«¯ï¼Œä½†å¼€å¯æµå¼å“åº”
            response = client.chat.completions.create(**api_params)
            
            api_logger.debug(f"è·å–åˆ°æµå¼å“åº”: {type(response)}")
            
            # è¿™é‡Œresponseæ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œéœ€è¦éå†æ¯ä¸ªéƒ¨åˆ†
            collected_content = ""
            collected_tool_calls = []
            is_first_chunk = True
            chunk_count = 0
            
            for chunk in response:
                # è®°å½•æµå¼å“åº”çš„æ¯ä¸ªå—çš„åŸå§‹å†…å®¹
                chunk_count += 1
                api_logger.debug(f"æµå¼å“åº”å— #{chunk_count}: {json.dumps(chunk.model_dump(), ensure_ascii=False)}")
                
                if hasattr(chunk, 'choices') and chunk.choices:
                    delta = chunk.choices[0].delta
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                    if hasattr(delta, 'tool_calls') and delta.tool_calls:
                        api_logger.debug(f"æµå¼å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(delta.tool_calls)} ä¸ª")
                        
                        # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯
                        for tool_call in delta.tool_calls:
                            # è·å–å·¥å…·è°ƒç”¨çš„ç´¢å¼•ï¼ˆå¦‚æœæœ‰ï¼‰
                            tool_index = getattr(tool_call, 'index', None)
                            
                            # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç´¢å¼•çš„å·¥å…·è°ƒç”¨
                            existing_call = None
                            if tool_index is not None:
                                # ä½¿ç”¨ç´¢å¼•æŸ¥æ‰¾
                                if tool_index < len(collected_tool_calls):
                                    existing_call = collected_tool_calls[tool_index]
                            else:
                                # ä½¿ç”¨IDæŸ¥æ‰¾
                                for existing in collected_tool_calls:
                                    if existing.get('id') == tool_call.id:
                                        existing_call = existing
                                        break
                            
                            if existing_call:
                                # æ›´æ–°ç°æœ‰çš„å·¥å…·è°ƒç”¨
                                if tool_call.function and tool_call.function.arguments:
                                    existing_call['function']['arguments'] += tool_call.function.arguments
                                    api_logger.debug(f"ç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°: {existing_call['id']}, å½“å‰å‚æ•°: {existing_call['function']['arguments']}")
                                
                                # æ›´æ–°å‡½æ•°åï¼ˆå¦‚æœæä¾›ï¼‰
                                if tool_call.function and tool_call.function.name:
                                    existing_call['function']['name'] = tool_call.function.name
                                
                                # æ›´æ–°IDï¼ˆå¦‚æœæä¾›ï¼‰
                                if tool_call.id:
                                    existing_call['id'] = tool_call.id
                            else:
                                # æ·»åŠ æ–°çš„å·¥å…·è°ƒç”¨
                                new_call = {
                                    'id': tool_call.id if tool_call.id else f"call_{len(collected_tool_calls)}",
                                    'type': tool_call.type if tool_call.type else 'function',
                                    'function': {
                                        'name': tool_call.function.name if tool_call.function and tool_call.function.name else '',
                                        'arguments': tool_call.function.arguments if tool_call.function and tool_call.function.arguments else ''
                                    }
                                }
                                
                                # å¦‚æœæœ‰ç´¢å¼•ï¼Œç¡®ä¿åˆ—è¡¨è¶³å¤Ÿå¤§
                                if tool_index is not None:
                                    while len(collected_tool_calls) <= tool_index:
                                        collected_tool_calls.append(None)
                                    collected_tool_calls[tool_index] = new_call
                                else:
                                    collected_tool_calls.append(new_call)
                                
                                api_logger.debug(f"æ–°å¢å·¥å…·è°ƒç”¨: {new_call['id']}, åç§°: {new_call['function']['name']}, åˆå§‹å‚æ•°: {new_call['function']['arguments']}")
                                
                                # å‘é€å·¥å…·è°ƒç”¨å¼€å§‹çš„çŠ¶æ€ä¿¡æ¯
                                tool_status = {
                                    "type": "tool_call_start",
                                    "tool_call_id": new_call['id'],
                                    "tool_name": new_call['function']['name'],
                                    "status": "preparing"
                                }
                                yield ("", conversation_id, tool_status)
                    
                    # æå–å½“å‰å—çš„å†…å®¹
                    content = delta.content or ""
                    
                    # ç´¯åŠ å†…å®¹
                    collected_content += content
                    
                    # å¯¹ç¬¬ä¸€ä¸ªæœ‰å†…å®¹çš„å—ç‰¹æ®Šå¤„ç†
                    if is_first_chunk and content:
                        is_first_chunk = False
                        # å¯¹ç¬¬ä¸€ä¸ªå—ï¼Œæˆ‘ä»¬æ€»æ˜¯è¿”å›ä¼šè¯IDï¼Œä¸ç®¡æ˜¯å¦æ˜¯æ–°ä¼šè¯
                        yield (content, conversation_id)
                    elif content:
                        # åç»­å—åªè¿”å›å†…å®¹
                        yield content
            
            # æµå¼å“åº”ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨éœ€è¦å¤„ç†
            api_logger.info(f"æµå¼å“åº”å®Œæˆï¼Œå…±æ¥æ”¶ {chunk_count} ä¸ªå—")
            api_logger.info(f"æµå¼å“åº”å®Œæ•´å†…å®¹: {collected_content}")
            api_logger.info(f"æ”¶é›†åˆ°çš„å·¥å…·è°ƒç”¨: {len(collected_tool_calls)} ä¸ª")
            
            # é€ä¸ªå¤„ç†å·¥å…·è°ƒç”¨ï¼Œå‘é€çŠ¶æ€æ›´æ–°
            tool_results = []
            all_tool_calls_data = []
            
            # æ„é€ å·¥å…·è°ƒç”¨å¯¹è±¡
            class ToolCall:
                def __init__(self, id, type, function):
                    self.id = id
                    self.type = type
                    self.function = function
            
            class Function:
                def __init__(self, name, arguments):
                    self.name = name
                    self.arguments = arguments
            
            for tc in collected_tool_calls:
                if tc is None:
                    continue
                    
                # æ„é€ å·¥å…·è°ƒç”¨å¯¹è±¡
                func = Function(tc['function']['name'], tc['function']['arguments'])
                tool_call_obj = ToolCall(tc['id'], tc['type'], func)
                
                # å‘é€å·¥å…·è°ƒç”¨æ‰§è¡ŒçŠ¶æ€
                tool_status = {
                    "type": "tool_call_executing",
                    "tool_call_id": tool_call_obj.id,
                    "tool_name": tool_call_obj.function.name,
                    "status": "executing"
                }
                yield ("", conversation_id, tool_status)
                
                # æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨
                single_result, single_tool_data = await handle_tool_calls([tool_call_obj], current_agent, db, conversation_id)
                tool_results.extend(single_result)
                all_tool_calls_data.extend(single_tool_data)
                
                # å‘é€å·¥å…·è°ƒç”¨å®ŒæˆçŠ¶æ€ï¼ŒåŒ…å«ç»“æœå†…å®¹
                tool_result_content = single_result[0]["content"] if single_result else ""
                tool_status = {
                    "type": "tool_call_completed",
                    "tool_call_id": tool_call_obj.id,
                    "tool_name": tool_call_obj.function.name,
                    "status": "completed",
                    "result": tool_result_content  # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœ
                }
                yield ("", conversation_id, tool_status)
                
                # åœ¨å·¥å…·è°ƒç”¨å®Œæˆåï¼Œå‘é€ä¸€ä¸ªç‰¹æ®Šçš„æ–‡æœ¬æ ‡è®°ï¼Œè¡¨ç¤ºå·¥å…·è°ƒç”¨å·²å®Œæˆ
                tool_completion_text = f"\n\nğŸ”§ {tool_call_obj.function.name} æ‰§è¡Œå®Œæˆ\n\n"
                yield (tool_completion_text, conversation_id)
            
            # é€’å½’å¤„ç†å·¥å…·è°ƒç”¨ï¼Œæ”¯æŒæ— é™æ¬¡è°ƒç”¨
            async for content_chunk in process_tool_calls_recursively_stream(
                collected_content, 
                collected_tool_calls, 
                messages, 
                current_agent, 
                use_model, 
                max_tokens, 
                temperature, 
                top_p, 
                tools, 
                has_tools, 
                conversation_id,
                db
            ):
                if isinstance(content_chunk, tuple):
                    # å·¥å…·çŠ¶æ€ä¿¡æ¯
                    yield content_chunk
                else:
                    # å†…å®¹å—
                    yield content_chunk
                    collected_content += content_chunk
            
            # ä¿å­˜æœ€ç»ˆå†…å®¹åˆ°æ•°æ®åº“
            if db and user_id and conversation_id and collected_content:
                # ä¼°ç®—tokenæ•°é‡ï¼ˆç®€å•å®ç°ï¼‰
                tokens = len(collected_content) // 4
                prompt_tokens = len(str(messages)) // 4
                total_tokens = tokens + prompt_tokens
                
                # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œéœ€è¦æ”¶é›†å·¥å…·è°ƒç”¨æ•°æ®
                final_tool_calls_data = None
                if collected_tool_calls:
                    # è¿™é‡Œéœ€è¦ä»å·¥å…·è°ƒç”¨å¤„ç†ä¸­è·å–å®Œæ•´çš„å·¥å…·è°ƒç”¨æ•°æ®
                    # ç”±äºæµå¼å¤„ç†çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å…ˆä¿å­˜åŸºæœ¬ä¿¡æ¯
                    final_tool_calls_data = []
                    for tc in collected_tool_calls:
                        if tc:  # è·³è¿‡Noneå€¼
                            final_tool_calls_data.append({
                                "id": tc.get("id", ""),
                                "name": tc.get("function", {}).get("name", ""),
                                "arguments": json.loads(tc.get("function", {}).get("arguments", "{}")),
                                "status": "completed",  # æµå¼å“åº”å®Œæˆæ—¶é»˜è®¤ä¸ºcompleted
                                "result": None,  # åœ¨é€’å½’å¤„ç†ä¸­ä¼šæ›´æ–°
                                "error": None,
                                "started_at": datetime.now().isoformat(),
                                "completed_at": datetime.now().isoformat()
                            })
                
                await add_message(
                    db=db,
                    conversation_id=conversation_id,
                    role="assistant",
                    content=collected_content,
                    tokens=tokens,
                    prompt_tokens=prompt_tokens,
                    total_tokens=total_tokens,
                    agent_id=agent_id,
                    tool_calls_data=final_tool_calls_data
                )
                
                # ä¿å­˜åˆ°è®°å¿†
                memory_service.add_assistant_message(conversation_id, collected_content, user_id)
                
                api_logger.info(f"æµå¼èŠå¤©å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(collected_content)}")
        
        except Exception as api_error:
            api_logger.error(f"æµå¼APIè°ƒç”¨å‡ºé”™: {str(api_error)}", exc_info=True)
            
            # å¦‚æœæ˜¯å› ä¸ºæ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹
            if "æ— å¯ç”¨æ¸ é“" in str(api_error) and current_agent and use_model != model:
                api_logger.info(f"æµå¼æ¥å£å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹ {model} é‡æ–°è¯·æ±‚")
                try:
                    # å‡†å¤‡é»˜è®¤æ¨¡å‹çš„APIè°ƒç”¨å‚æ•°
                    fallback_api_params = {
                        "model": model,
                        "messages": messages,
                        "max_tokens": max_tokens,
                        "temperature": temperature,
                        "top_p": top_p,
                        "stream": True  # ä»ç„¶ä¿æŒæµå¼å“åº”
                    }
                    
                    # å¦‚æœæœ‰å·¥å…·ï¼Œæ·»åŠ å·¥å…·é…ç½®
                    if has_tools:
                        fallback_api_params["tools"] = tools
                    
                    # ä½¿ç”¨é»˜è®¤æ¨¡å‹é‡è¯•
                    response = client.chat.completions.create(**fallback_api_params)
                    
                    api_logger.debug(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹è·å–åˆ°æµå¼å“åº”: {type(response)}")
                    
                    # è¿™é‡Œresponseæ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œéœ€è¦éå†æ¯ä¸ªéƒ¨åˆ†
                    collected_content = ""
                    collected_tool_calls = []
                    is_first_chunk = True
                    chunk_count = 0
                    
                    for chunk in response:
                        # è®°å½•æµå¼å“åº”çš„æ¯ä¸ªå—çš„åŸå§‹å†…å®¹
                        chunk_count += 1
                        api_logger.debug(f"æµå¼å“åº”å— #{chunk_count}: {json.dumps(chunk.model_dump(), ensure_ascii=False)}")
                        
                        if hasattr(chunk, 'choices') and chunk.choices:
                            delta = chunk.choices[0].delta
                            
                            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                            if hasattr(delta, 'tool_calls') and delta.tool_calls:
                                api_logger.info(f"æµå¼å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(delta.tool_calls)} ä¸ª")
                                
                                # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯
                                for tool_call in delta.tool_calls:
                                    # è·å–å·¥å…·è°ƒç”¨çš„ç´¢å¼•ï¼ˆå¦‚æœæœ‰ï¼‰
                                    tool_index = getattr(tool_call, 'index', None)
                                    
                                    # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç´¢å¼•çš„å·¥å…·è°ƒç”¨
                                    existing_call = None
                                    if tool_index is not None:
                                        # ä½¿ç”¨ç´¢å¼•æŸ¥æ‰¾
                                        if tool_index < len(collected_tool_calls):
                                            existing_call = collected_tool_calls[tool_index]
                                    else:
                                        # ä½¿ç”¨IDæŸ¥æ‰¾
                                        for existing in collected_tool_calls:
                                            if existing.get('id') == tool_call.id:
                                                existing_call = existing
                                                break
                                    
                                    if existing_call:
                                        # æ›´æ–°ç°æœ‰çš„å·¥å…·è°ƒç”¨
                                        if tool_call.function and tool_call.function.arguments:
                                            existing_call['function']['arguments'] += tool_call.function.arguments
                                            api_logger.debug(f"ç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°: {existing_call['id']}, å½“å‰å‚æ•°: {existing_call['function']['arguments']}")
                                        
                                        # æ›´æ–°å‡½æ•°åï¼ˆå¦‚æœæä¾›ï¼‰
                                        if tool_call.function and tool_call.function.name:
                                            existing_call['function']['name'] = tool_call.function.name
                                        
                                        # æ›´æ–°IDï¼ˆå¦‚æœæä¾›ï¼‰
                                        if tool_call.id:
                                            existing_call['id'] = tool_call.id
                                    else:
                                        # æ·»åŠ æ–°çš„å·¥å…·è°ƒç”¨
                                        new_call = {
                                            'id': tool_call.id if tool_call.id else f"call_{len(collected_tool_calls)}",
                                            'type': tool_call.type if tool_call.type else 'function',
                                            'function': {
                                                'name': tool_call.function.name if tool_call.function and tool_call.function.name else '',
                                                'arguments': tool_call.function.arguments if tool_call.function and tool_call.function.arguments else ''
                                            }
                                        }
                                        
                                        # å¦‚æœæœ‰ç´¢å¼•ï¼Œç¡®ä¿åˆ—è¡¨è¶³å¤Ÿå¤§
                                        if tool_index is not None:
                                            while len(collected_tool_calls) <= tool_index:
                                                collected_tool_calls.append(None)
                                            collected_tool_calls[tool_index] = new_call
                                        else:
                                            collected_tool_calls.append(new_call)
                                        
                                        api_logger.debug(f"æ–°å¢å·¥å…·è°ƒç”¨: {new_call['id']}, åç§°: {new_call['function']['name']}, åˆå§‹å‚æ•°: {new_call['function']['arguments']}")
                            
                            # æå–å½“å‰å—çš„å†…å®¹
                            content = delta.content or ""
                            
                            # ç´¯åŠ å†…å®¹
                            collected_content += content
                            
                            # å¯¹ç¬¬ä¸€ä¸ªæœ‰å†…å®¹çš„å—ç‰¹æ®Šå¤„ç†
                            if is_first_chunk and content:
                                is_first_chunk = False
                                # å¯¹ç¬¬ä¸€ä¸ªå—ï¼Œæˆ‘ä»¬æ€»æ˜¯è¿”å›ä¼šè¯IDï¼Œä¸ç®¡æ˜¯å¦æ˜¯æ–°ä¼šè¯
                                yield (content, conversation_id)
                            elif content:
                                # åç»­å—åªè¿”å›å†…å®¹
                                yield content
                    
                    # æµå¼å“åº”ç»“æŸï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨éœ€è¦å¤„ç†
                    api_logger.info(f"æµå¼å“åº”å®Œæˆï¼Œå…±æ¥æ”¶ {chunk_count} ä¸ªå—")
                    api_logger.info(f"æµå¼å“åº”å®Œæ•´å†…å®¹: {collected_content}")
                    api_logger.info(f"æ”¶é›†åˆ°çš„å·¥å…·è°ƒç”¨: {len(collected_tool_calls)} ä¸ª")
                    
                    # é€ä¸ªå¤„ç†å·¥å…·è°ƒç”¨ï¼Œå‘é€çŠ¶æ€æ›´æ–°
                    tool_results = []
                    all_tool_calls_data = []
                    
                    for tool_call_obj in collected_tool_calls:
                        # å‘é€å·¥å…·è°ƒç”¨æ‰§è¡ŒçŠ¶æ€
                        tool_status = {
                            "type": "tool_call_executing",
                            "tool_call_id": tool_call_obj.id,
                            "tool_name": tool_call_obj.function.name,
                            "status": "executing"
                        }
                        yield ("", conversation_id, tool_status)
                        
                        # æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨
                        single_result, single_tool_data = await handle_tool_calls([tool_call_obj], current_agent, db, conversation_id)
                        tool_results.extend(single_result)
                        all_tool_calls_data.extend(single_tool_data)
                        
                        # å‘é€å·¥å…·è°ƒç”¨å®ŒæˆçŠ¶æ€ï¼ŒåŒ…å«ç»“æœå†…å®¹
                        tool_result_content = single_result[0]["content"] if single_result else ""
                        tool_status = {
                            "type": "tool_call_completed",
                            "tool_call_id": tool_call_obj.id,
                            "tool_name": tool_call_obj.function.name,
                            "status": "completed",
                            "result": tool_result_content  # æ·»åŠ å·¥å…·è°ƒç”¨ç»“æœ
                        }
                        yield ("", conversation_id, tool_status)
                        
                        # åœ¨å·¥å…·è°ƒç”¨å®Œæˆåï¼Œå‘é€ä¸€ä¸ªç‰¹æ®Šçš„æ–‡æœ¬æ ‡è®°ï¼Œè¡¨ç¤ºå·¥å…·è°ƒç”¨å·²å®Œæˆ
                        tool_completion_text = f"\n\nğŸ”§ {tool_call_obj.function.name} æ‰§è¡Œå®Œæˆ\n\n"
                        yield (tool_completion_text, conversation_id)
                    
                    # é€’å½’å¤„ç†å·¥å…·è°ƒç”¨ï¼Œæ”¯æŒæ— é™æ¬¡è°ƒç”¨
                    async for content_chunk in process_tool_calls_recursively_stream(
                        collected_content, 
                        collected_tool_calls, 
                        messages, 
                        current_agent, 
                        use_model, 
                        max_tokens, 
                        temperature, 
                        top_p, 
                        tools, 
                        has_tools, 
                        conversation_id,
                        db
                    ):
                        if isinstance(content_chunk, tuple):
                            # å·¥å…·çŠ¶æ€ä¿¡æ¯
                            yield content_chunk
                        else:
                            # å†…å®¹å—
                            yield content_chunk
                            collected_content += content_chunk
                    
                    # ä¿å­˜æœ€ç»ˆå†…å®¹åˆ°æ•°æ®åº“
                    if db and user_id and conversation_id and collected_content:
                        # ä¼°ç®—tokenæ•°é‡ï¼ˆç®€å•å®ç°ï¼‰
                        tokens = len(collected_content) // 4
                        prompt_tokens = len(str(messages)) // 4
                        total_tokens = tokens + prompt_tokens
                        
                        await add_message(
                            db=db,
                            conversation_id=conversation_id,
                            role="assistant",
                            content=collected_content,
                            tokens=tokens,
                            prompt_tokens=prompt_tokens,
                            total_tokens=total_tokens,
                            agent_id=agent_id,
                            tool_calls_data=all_tool_calls_data
                        )
                        
                        # ä¿å­˜åˆ°è®°å¿†
                        memory_service.add_assistant_message(conversation_id, collected_content, user_id)
                        
                        api_logger.info(f"æµå¼èŠå¤©å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(collected_content)}")
                
                except Exception as fallback_error:
                    api_logger.error(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹ {model} æµå¼å“åº”ä»ç„¶å¤±è´¥: {str(fallback_error)}", exc_info=True)
            
            # å‘é€é”™è¯¯ä¿¡æ¯ä½œä¸ºæµå¼å†…å®¹
            error_message = f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(api_error)}"
            
            # æ€»æ˜¯è¿”å›ä¼šè¯IDï¼Œä¸ç®¡æ˜¯å¦æ˜¯æ–°ä¼šè¯
            yield (error_message, conversation_id)
            
            # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“
            if db and user_id and conversation_id:
                await add_message(
                    db=db,
                    conversation_id=conversation_id,
                    role="assistant",
                    content=error_message
                )
    
    except Exception as e:
        api_logger.error(f"æµå¼èŠå¤©ç”Ÿæˆå¤±è´¥: {str(e)}", exc_info=True)
        
        # å‘é€ä¸€ä¸ªé”™è¯¯æ¶ˆæ¯ï¼ŒåŒ…å«ä¼šè¯ID
        error_message = f"AIæœåŠ¡å‘ç”Ÿé”™è¯¯: {str(e)}"
        yield (error_message, conversation_id)


async def clear_memory(conversation_id: int):
    """
    æ¸…ç©ºæŒ‡å®šä¼šè¯çš„è®°å¿†
    """
    memory_service.clear_memory(conversation_id)
    api_logger.info(f"å·²æ¸…ç©ºä¼šè¯ {conversation_id} çš„è®°å¿†")


async def truncate_memory_after_message(conversation_id: int, message_index: int) -> bool:
    """
    æˆªæ–­æŒ‡å®šæ¶ˆæ¯åçš„æ‰€æœ‰è®°å¿†
    
    Args:
        conversation_id: ä¼šè¯ID
        message_index: æ¶ˆæ¯ç´¢å¼•ï¼Œä¿ç•™è¯¥ç´¢å¼•åŠä¹‹å‰çš„æ¶ˆæ¯ï¼Œåˆ é™¤ä¹‹åçš„æ¶ˆæ¯
    
    Returns:
        bool: æ˜¯å¦æˆªæ–­æˆåŠŸ
    """
    result = memory_service.truncate_memory_after_message(conversation_id, message_index)
    if result:
        api_logger.info(f"å·²æˆªæ–­ä¼šè¯ {conversation_id} çš„è®°å¿†ï¼Œä¿ç•™åˆ°ç´¢å¼• {message_index}")
    else:
        api_logger.warning(f"æˆªæ–­ä¼šè¯ {conversation_id} çš„è®°å¿†å¤±è´¥")
    return result


async def replace_message_and_truncate(conversation_id: int, message_index: int, new_content: str, role: str = None) -> bool:
    """
    æ›¿æ¢æŒ‡å®šæ¶ˆæ¯çš„å†…å®¹ï¼Œå¹¶æˆªæ–­è¯¥æ¶ˆæ¯ä¹‹åçš„æ‰€æœ‰è®°å¿†
    
    Args:
        conversation_id: ä¼šè¯ID
        message_index: æ¶ˆæ¯ç´¢å¼•
        new_content: æ–°çš„æ¶ˆæ¯å†…å®¹
        role: æ¶ˆæ¯è§’è‰²ï¼Œå¦‚æœä¸ºNoneåˆ™ä¿æŒåŸè§’è‰²
    
    Returns:
        bool: æ˜¯å¦æ“ä½œæˆåŠŸ
    """
    result = memory_service.replace_message_and_truncate(conversation_id, message_index, new_content, role)
    if result:
        api_logger.info(f"å·²æ›¿æ¢ä¼šè¯ {conversation_id} çš„æ¶ˆæ¯ {message_index} å¹¶æˆªæ–­åç»­æ¶ˆæ¯")
    else:
        api_logger.warning(f"æ›¿æ¢ä¼šè¯ {conversation_id} çš„æ¶ˆæ¯å¤±è´¥")
    return result


async def get_chat_history(
    db: AsyncSession, 
    conversation_id: int, 
    user_id: int
) -> List[Dict[str, Any]]:
    """
    è·å–æŒ‡å®šä¼šè¯çš„èŠå¤©å†å²è®°å½•
    """
    # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    chat = await get_chat(db, conversation_id)
    if not chat or chat.user_id != user_id:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail="èŠå¤©ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
        )
    
    # è·å–èŠå¤©æ¶ˆæ¯
    messages = await get_chat_messages(db, conversation_id)
    
    # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
    return [
        {
            "id": msg.id,
            "role": msg.role,
            "content": msg.content,
            "created_at": msg.created_at.isoformat() if msg.created_at else None
        }
        for msg in messages
    ]


async def process_tool_calls_recursively(
    content: str, 
    tool_calls: List[Dict[str, Any]], 
    messages: List[Dict[str, Any]], 
    agent, 
    use_model: str, 
    max_tokens: int, 
    temperature: float, 
    top_p: float, 
    tools: List[Dict[str, Any]], 
    has_tools: bool, 
    conversation_id: int,
    max_iterations: int = 10  # é˜²æ­¢æ— é™å¾ªç¯
) -> str:
    """
    é€’å½’å¤„ç†å·¥å…·è°ƒç”¨ï¼Œæ”¯æŒæ— é™æ¬¡è°ƒç”¨
    """
    iteration = 0
    current_content = content
    current_tool_calls = tool_calls
    
    while current_tool_calls and iteration < max_iterations:
        iteration += 1
        api_logger.info(f"å¼€å§‹ç¬¬ {iteration} è½®å·¥å…·è°ƒç”¨å¤„ç†ï¼Œå…± {len(current_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        
        # éªŒè¯å·¥å…·è°ƒç”¨å‚æ•°çš„å®Œæ•´æ€§
        valid_tool_calls = []
        for tc in current_tool_calls:
            # è·³è¿‡Noneå€¼ï¼ˆå¯èƒ½ç”±ç´¢å¼•å¡«å……äº§ç”Ÿï¼‰
            if tc is None:
                continue
                
            # æ£€æŸ¥å‡½æ•°åæ˜¯å¦æœ‰æ•ˆ
            if not tc['function']['name']:
                api_logger.warning(f"å·¥å…·è°ƒç”¨ {tc['id']} å‡½æ•°åä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥å‚æ•°æ˜¯å¦æœ‰æ•ˆ
            if tc['function']['arguments'].strip():
                try:
                    # éªŒè¯JSONæ ¼å¼
                    json.loads(tc['function']['arguments'])
                    valid_tool_calls.append(tc)
                    api_logger.info(f"å·¥å…·è°ƒç”¨ {tc['function']['name']} å‚æ•°å®Œæ•´: {tc['function']['arguments']}")
                except json.JSONDecodeError as e:
                    api_logger.error(f"å·¥å…·è°ƒç”¨ {tc['function']['name']} å‚æ•°JSONæ ¼å¼é”™è¯¯: {tc['function']['arguments']}, é”™è¯¯: {e}")
            else:
                api_logger.warning(f"å·¥å…·è°ƒç”¨ {tc['function']['name']} å‚æ•°ä¸ºç©ºï¼Œè·³è¿‡")
        
        if not valid_tool_calls:
            api_logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·è°ƒç”¨ï¼Œç»“æŸå·¥å…·å¤„ç†")
            break
        
        # æ„é€ å·¥å…·è°ƒç”¨å¯¹è±¡
        class ToolCall:
            def __init__(self, id, type, function):
                self.id = id
                self.type = type
                self.function = function
        
        class Function:
            def __init__(self, name, arguments):
                self.name = name
                self.arguments = arguments
        
        tool_call_objects = []
        for tc in valid_tool_calls:
            func = Function(tc['function']['name'], tc['function']['arguments'])
            tool_call_obj = ToolCall(tc['id'], tc['type'], func)
            tool_call_objects.append(tool_call_obj)
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        tool_results, tool_calls_data = await handle_tool_calls(tool_call_objects, agent, db, conversation_id)
        
        # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
        messages.append({
            "role": "assistant",
            "content": current_content,
            "tool_calls": [
                {
                    "id": tc['id'],
                    "type": "function",
                    "function": {
                        "name": tc['function']['name'],
                        "arguments": tc['function']['arguments']
                    }
                } for tc in valid_tool_calls
            ]
        })
        
        # æ·»åŠ å·¥å…·ç»“æœ
        for tool_result in tool_results:
            messages.append(tool_result)
        
        api_logger.info(f"ç¬¬ {iteration} è½®å·¥å…·è°ƒç”¨å®Œæˆï¼Œè°ƒç”¨ä¸‹ä¸€æ¬¡API")
        
        # è°ƒç”¨APIè·å–ä¸‹ä¸€æ¬¡å“åº”
        next_response = client.chat.completions.create(
            model=use_model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            stream=False,
            tools=tools if has_tools else None  # ç¡®ä¿æ¯æ¬¡è°ƒç”¨éƒ½åŒ…å«å·¥å…·é…ç½®
        )
        
        # æå–å“åº”
        assistant_message = next_response.choices[0].message
        current_content = assistant_message.content or ""
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å·¥å…·è°ƒç”¨
        new_tool_calls = assistant_message.tool_calls if hasattr(assistant_message, 'tool_calls') else None
        
        if new_tool_calls:
            api_logger.info(f"ç¬¬ {iteration} è½®å“åº”ä¸­æ£€æµ‹åˆ°æ–°çš„å·¥å…·è°ƒç”¨: {len(new_tool_calls)} ä¸ª")
            
            # è½¬æ¢å·¥å…·è°ƒç”¨æ ¼å¼
            current_tool_calls = []
            for tc in new_tool_calls:
                current_tool_calls.append({
                    'id': tc.id,
                    'type': tc.type,
                    'function': {
                        'name': tc.function.name,
                        'arguments': tc.function.arguments
                    }
                })
        else:
            api_logger.info(f"ç¬¬ {iteration} è½®å“åº”ä¸­æ²¡æœ‰æ–°çš„å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¤„ç†")
            current_tool_calls = None
    
    if iteration >= max_iterations:
        api_logger.warning(f"å·¥å…·è°ƒç”¨è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}ï¼Œå¼ºåˆ¶ç»“æŸ")
    
    api_logger.info(f"å·¥å…·è°ƒç”¨å¤„ç†å®Œæˆï¼Œå…±è¿›è¡Œäº† {iteration} è½®ï¼Œæœ€ç»ˆå†…å®¹é•¿åº¦: {len(current_content)}")
    return current_content 


async def process_tool_calls_recursively_stream(
    content: str, 
    tool_calls: List[Dict[str, Any]], 
    messages: List[Dict[str, Any]], 
    agent, 
    use_model: str, 
    max_tokens: int, 
    temperature: float, 
    top_p: float, 
    tools: List[Dict[str, Any]], 
    has_tools: bool, 
    conversation_id: int,
    db: Optional[AsyncSession] = None,
    max_iterations: int = 10  # é˜²æ­¢æ— é™å¾ªç¯
):
    """
    é€’å½’å¤„ç†å·¥å…·è°ƒç”¨ï¼Œæ”¯æŒæ— é™æ¬¡è°ƒç”¨ï¼ˆæµå¼ç‰ˆæœ¬ï¼‰
    """
    iteration = 0
    current_content = content
    current_tool_calls = tool_calls
    
    while current_tool_calls and iteration < max_iterations:
        iteration += 1
        api_logger.info(f"å¼€å§‹ç¬¬ {iteration} è½®å·¥å…·è°ƒç”¨å¤„ç†ï¼Œå…± {len(current_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        
        # éªŒè¯å·¥å…·è°ƒç”¨å‚æ•°çš„å®Œæ•´æ€§
        valid_tool_calls = []
        for tc in current_tool_calls:
            # è·³è¿‡Noneå€¼ï¼ˆå¯èƒ½ç”±ç´¢å¼•å¡«å……äº§ç”Ÿï¼‰
            if tc is None:
                continue
                
            # æ£€æŸ¥å‡½æ•°åæ˜¯å¦æœ‰æ•ˆ
            if not tc['function']['name']:
                api_logger.warning(f"å·¥å…·è°ƒç”¨ {tc['id']} å‡½æ•°åä¸ºç©ºï¼Œè·³è¿‡")
                continue
            
            # æ£€æŸ¥å‚æ•°æ˜¯å¦æœ‰æ•ˆ
            if tc['function']['arguments'].strip():
                try:
                    # éªŒè¯JSONæ ¼å¼
                    json.loads(tc['function']['arguments'])
                    valid_tool_calls.append(tc)
                    api_logger.info(f"å·¥å…·è°ƒç”¨ {tc['function']['name']} å‚æ•°å®Œæ•´: {tc['function']['arguments']}")
                except json.JSONDecodeError as e:
                    api_logger.error(f"å·¥å…·è°ƒç”¨ {tc['function']['name']} å‚æ•°JSONæ ¼å¼é”™è¯¯: {tc['function']['arguments']}, é”™è¯¯: {e}")
            else:
                api_logger.warning(f"å·¥å…·è°ƒç”¨ {tc['function']['name']} å‚æ•°ä¸ºç©ºï¼Œè·³è¿‡")
        
        if not valid_tool_calls:
            api_logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„å·¥å…·è°ƒç”¨ï¼Œç»“æŸå·¥å…·å¤„ç†")
            break
        
        # æ„é€ å·¥å…·è°ƒç”¨å¯¹è±¡
        class ToolCall:
            def __init__(self, id, type, function):
                self.id = id
                self.type = type
                self.function = function
        
        class Function:
            def __init__(self, name, arguments):
                self.name = name
                self.arguments = arguments
        
        tool_call_objects = []
        for tc in valid_tool_calls:
            func = Function(tc['function']['name'], tc['function']['arguments'])
            tool_call_obj = ToolCall(tc['id'], tc['type'], func)
            tool_call_objects.append(tool_call_obj)
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        tool_results, tool_calls_data = await handle_tool_calls(tool_call_objects, agent, db, conversation_id)
        
        # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
        messages.append({
            "role": "assistant",
            "content": current_content,
            "tool_calls": [
                {
                    "id": tc['id'],
                    "type": "function",
                    "function": {
                        "name": tc['function']['name'],
                        "arguments": tc['function']['arguments']
                    }
                } for tc in valid_tool_calls
            ]
        })
        
        # æ·»åŠ å·¥å…·ç»“æœ
        for tool_result in tool_results:
            messages.append(tool_result)
        
        api_logger.info(f"ç¬¬ {iteration} è½®å·¥å…·è°ƒç”¨å®Œæˆï¼Œè°ƒç”¨ä¸‹ä¸€æ¬¡æµå¼API")
        
        # è°ƒç”¨APIè·å–ä¸‹ä¸€æ¬¡å“åº”ï¼ˆæµå¼ï¼‰
        next_response = client.chat.completions.create(
            model=use_model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            stream=True,
            tools=tools if has_tools else None  # ç¡®ä¿æ¯æ¬¡è°ƒç”¨éƒ½åŒ…å«å·¥å…·é…ç½®
        )
        
        # å¤„ç†æµå¼å“åº”
        next_collected_content = ""
        next_collected_tool_calls = []
        next_chunk_count = 0
        
        for chunk in next_response:
            next_chunk_count += 1
            api_logger.debug(f"ç¬¬ {iteration} è½®æµå¼å“åº”å— #{next_chunk_count}: {json.dumps(chunk.model_dump(), ensure_ascii=False)}")
            
            if hasattr(chunk, 'choices') and chunk.choices:
                delta = chunk.choices[0].delta
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                if hasattr(delta, 'tool_calls') and delta.tool_calls:
                    api_logger.debug(f"ç¬¬ {iteration} è½®æµå¼å“åº”ä¸­æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(delta.tool_calls)} ä¸ª")
                    
                    # æ”¶é›†å·¥å…·è°ƒç”¨ä¿¡æ¯
                    for tool_call in delta.tool_calls:
                        # è·å–å·¥å…·è°ƒç”¨çš„ç´¢å¼•ï¼ˆå¦‚æœæœ‰ï¼‰
                        tool_index = getattr(tool_call, 'index', None)
                        
                        # æŸ¥æ‰¾æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç´¢å¼•çš„å·¥å…·è°ƒç”¨
                        existing_call = None
                        if tool_index is not None:
                            # ä½¿ç”¨ç´¢å¼•æŸ¥æ‰¾
                            if tool_index < len(next_collected_tool_calls):
                                existing_call = next_collected_tool_calls[tool_index]
                        else:
                            # ä½¿ç”¨IDæŸ¥æ‰¾
                            for existing in next_collected_tool_calls:
                                if existing and existing.get('id') == tool_call.id:
                                    existing_call = existing
                                    break
                        
                        if existing_call:
                            # æ›´æ–°ç°æœ‰çš„å·¥å…·è°ƒç”¨
                            if tool_call.function and tool_call.function.arguments:
                                existing_call['function']['arguments'] += tool_call.function.arguments
                                api_logger.debug(f"ç¬¬ {iteration} è½®ç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°: {existing_call['id']}, å½“å‰å‚æ•°: {existing_call['function']['arguments']}")
                            
                            # æ›´æ–°å‡½æ•°åï¼ˆå¦‚æœæä¾›ï¼‰
                            if tool_call.function and tool_call.function.name:
                                existing_call['function']['name'] = tool_call.function.name
                            
                            # æ›´æ–°IDï¼ˆå¦‚æœæä¾›ï¼‰
                            if tool_call.id:
                                existing_call['id'] = tool_call.id
                        else:
                            # æ·»åŠ æ–°çš„å·¥å…·è°ƒç”¨
                            new_call = {
                                'id': tool_call.id if tool_call.id else f"call_iter_{iteration}_{len(next_collected_tool_calls)}",
                                'type': tool_call.type if tool_call.type else 'function',
                                'function': {
                                    'name': tool_call.function.name if tool_call.function and tool_call.function.name else '',
                                    'arguments': tool_call.function.arguments if tool_call.function and tool_call.function.arguments else ''
                                }
                            }
                            
                            # å¦‚æœæœ‰ç´¢å¼•ï¼Œç¡®ä¿åˆ—è¡¨è¶³å¤Ÿå¤§
                            if tool_index is not None:
                                while len(next_collected_tool_calls) <= tool_index:
                                    next_collected_tool_calls.append(None)
                                next_collected_tool_calls[tool_index] = new_call
                            else:
                                next_collected_tool_calls.append(new_call)
                            
                            api_logger.debug(f"ç¬¬ {iteration} è½®æ–°å¢å·¥å…·è°ƒç”¨: {new_call['id']}, åç§°: {new_call['function']['name']}, åˆå§‹å‚æ•°: {new_call['function']['arguments']}")
                            
                            # å‘é€å·¥å…·è°ƒç”¨å¼€å§‹çš„çŠ¶æ€ä¿¡æ¯
                            tool_status = {
                                "type": "tool_call_start",
                                "tool_call_id": new_call['id'],
                                "tool_name": new_call['function']['name'],
                                "status": "preparing"
                            }
                            yield ("", conversation_id, tool_status)
                
                content_chunk = delta.content or ""
                next_collected_content += content_chunk
                
                if content_chunk:
                    yield content_chunk
        
        # æ›´æ–°å½“å‰å†…å®¹å’Œå·¥å…·è°ƒç”¨
        current_content = next_collected_content
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„å·¥å…·è°ƒç”¨éœ€è¦å¤„ç†
        if next_collected_tool_calls:
            # è¿‡æ»¤æ‰Noneå€¼
            current_tool_calls = [tc for tc in next_collected_tool_calls if tc is not None]
            api_logger.info(f"ç¬¬ {iteration} è½®å“åº”ä¸­æ£€æµ‹åˆ° {len(current_tool_calls)} ä¸ªæ–°çš„å·¥å…·è°ƒç”¨")
        else:
            api_logger.info(f"ç¬¬ {iteration} è½®å“åº”ä¸­æ²¡æœ‰æ–°çš„å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¤„ç†")
            current_tool_calls = None
    
    if iteration >= max_iterations:
        api_logger.warning(f"å·¥å…·è°ƒç”¨è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}ï¼Œå¼ºåˆ¶ç»“æŸ")
    
    api_logger.info(f"æµå¼å·¥å…·è°ƒç”¨å¤„ç†å®Œæˆï¼Œå…±è¿›è¡Œäº† {iteration} è½®ï¼Œæœ€ç»ˆå†…å®¹é•¿åº¦: {len(current_content)}")
    
    # å‘é€å·¥å…·å¤„ç†å®ŒæˆçŠ¶æ€
    if iteration > 0:
        tool_status = {
            "type": "tools_completed",
            "status": "completed"
        }
        yield ("", conversation_id, tool_status) 