from typing import Dict, List, Any, AsyncGenerator, Optional
from fastapi import HTTPException, status
from sqlalchemy.ext.asyncio import AsyncSession
import json
from datetime import datetime
import aiohttp
import base64

from backend.schemas.chat import Message, ChatRequest, ChatCompletionResponse
from backend.utils.logging import api_logger
from backend.crud.chat import create_chat, get_chat, add_message, update_chat_agent
from backend.crud.agent import agent as agent_crud
from backend.services.memory import memory_service
from backend.services.openai_client import openai_client_service
from backend.services.chat_tool_handler import chat_tool_handler
from backend.services.chat_tool_processor import chat_tool_processor
from backend.services.chat_session_manager import chat_session_manager
from backend.crud.note_session import note_session


class ChatResponseService:
    """èŠå¤©å“åº”æœåŠ¡"""
    
    @staticmethod
    async def _process_tool_calls_with_interaction_flow_non_stream(
        content: str,
        tool_calls: List[Any],
        messages: List[Dict[str, Any]],
        agent,
        use_model: str,
        max_tokens: int,
        temperature: float,
        top_p: float,
        tools: List[Dict[str, Any]],
        has_tools: bool,
        session_id: int,
        db: Optional[AsyncSession] = None,
        message_id: Optional[int] = None,
        interaction_flow: List[Dict[str, Any]] = None,
        user_id: Optional[int] = None
    ) -> str:
        """
        å¤„ç†å·¥å…·è°ƒç”¨å¹¶è®°å½•åˆ°äº¤äº’æµç¨‹ä¸­ï¼ˆéæµå¼ç‰ˆæœ¬ï¼‰
        """
        if interaction_flow is None:
            interaction_flow = []
        
        # å¦‚æœæœ‰åˆå§‹å†…å®¹ï¼Œå…ˆè®°å½•åˆ°äº¤äº’æµç¨‹
        if content and content.strip():
            interaction_flow.append({
                "type": "text",
                "content": content,
                "timestamp": datetime.now().isoformat()
            })
        
        # å¤„ç†å·¥å…·è°ƒç”¨
        if tool_calls:
            api_logger.info(f"æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨è¯·æ±‚: {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            # è·å–agentçš„æ•°æ®åº“IDï¼Œé¿å…åœ¨handle_tool_callsä¸­æ‡’åŠ è½½
            # ä¿®å¤ï¼šé¿å…åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è®¿é—®SQLAlchemyå…³ç³»å±æ€§
            agent_db_id = getattr(agent, 'id', None) if agent else None
            
            tool_results, tool_calls_data = await chat_tool_handler.handle_tool_calls(
                tool_calls, 
                agent, 
                db, 
                session_id,
                message_id=message_id,
                user_id=user_id,
                agent_id=agent_db_id  # ä¼ é€’agent_idï¼Œé¿å…æ‡’åŠ è½½
            )
            
            # è®°å½•å·¥å…·è°ƒç”¨åˆ°äº¤äº’æµç¨‹
            for i, tool_call in enumerate(tool_calls):
                tool_call_record = {
                    "type": "tool_call",
                    "id": tool_call.id,
                    "name": tool_call.function.name,
                    "arguments": json.loads(tool_call.function.arguments),
                    "status": "completed",
                    "started_at": datetime.now().isoformat(),
                    "completed_at": datetime.now().isoformat()
                }
                
                # æ·»åŠ ç»“æœ
                if i < len(tool_results):
                    try:
                        tool_call_record["result"] = json.loads(tool_results[i]["content"])
                    except (json.JSONDecodeError, KeyError):
                        tool_call_record["result"] = tool_results[i]["content"]
                
                interaction_flow.append(tool_call_record)
            
            # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
            messages.append({
                "role": "assistant",
                "content": content,
                "tool_calls": [
                    {
                        "id": tc.id,
                        "type": "function",
                        "function": {
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    } for tc in tool_calls
                ]
            })
            
            # æ·»åŠ å·¥å…·ç»“æœ
            for tool_result in tool_results:
                messages.append(tool_result)
            
            # é€’å½’å¤„ç†å·¥å…·è°ƒç”¨
            final_content = await chat_tool_processor.process_tool_calls_recursively(
                content, 
                [
                    {
                        'id': tc.id,
                        'type': tc.type,
                        'function': {
                            'name': tc.function.name,
                            'arguments': tc.function.arguments
                        }
                    } for tc in tool_calls
                ], 
                messages, 
                agent, 
                use_model, 
                max_tokens, 
                temperature, 
                top_p, 
                tools, 
                has_tools, 
                session_id,
                db,
                message_id=message_id,
                user_id=user_id
            )
            
            # å¦‚æœæœ‰é¢å¤–çš„å†…å®¹ï¼Œè®°å½•åˆ°äº¤äº’æµç¨‹
            additional_content = final_content[len(content):] if len(final_content) > len(content) else ""
            if additional_content.strip():
                interaction_flow.append({
                    "type": "text",
                    "content": additional_content,
                    "timestamp": datetime.now().isoformat()
                })
            
            return final_content
        
        return content
    
    @staticmethod
    async def generate_chat_response(
        chat_request: ChatRequest,
        session_id: int,
        db: Optional[AsyncSession] = None,
        user_id: Optional[int] = None
    ) -> ChatCompletionResponse:
        """
        è°ƒç”¨OpenAI APIç”Ÿæˆå¯¹è¯å“åº”ï¼Œå¹¶ä¿å­˜å¯¹è¯è®°å½•
        """
        try:
            api_logger.info(f"å¼€å§‹è°ƒç”¨OpenAI API, æ¨¡å‹: {openai_client_service.model}, APIåœ°å€: {openai_client_service.async_client.base_url}")
            
            # è·å–æˆ–ç¡®è®¤èŠå¤©ä¼šè¯ID
            session_id = session_id
            
            # è·å–Agentä¿¡æ¯
            agent_id = chat_request.agent_id
            current_agent = None
            
            # è®¾ç½®é»˜è®¤å‚æ•°
            use_model = openai_client_service.model
            max_tokens = 4000
            temperature = 0.7
            top_p = 1.0
            
            if agent_id and db:
                # è·å–Agentä¿¡æ¯
                current_agent = await agent_crud.get_agent_for_user(db, agent_id=agent_id, user_id=user_id)
                if not current_agent:
                    api_logger.warning(f"Agentä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®: agent_id={agent_id}, user_id={user_id}")
                    raise HTTPException(
                        status_code=status.HTTP_404_NOT_FOUND,
                        detail="Agentä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                    )
                api_logger.info(f"ä½¿ç”¨Agent: AIåŠ©æ‰‹, ID={current_agent.public_id}")
            
            # ä¼šè¯åˆ›å»ºæˆ–éªŒè¯
            if db and user_id:
                # è·å–æˆ–åˆ›å»ºèŠå¤©ä¼šè¯
                if not session_id:
                    # åˆ›å»ºæ–°çš„èŠå¤©ä¼šè¯
                    if hasattr(chat_request, "note_id") and chat_request.note_id:
                        # æŸ¥è¯¢ç¬”è®°ä¿¡æ¯ï¼Œè·å–æ ‡é¢˜
                        from backend.models.note import Note
                        from sqlalchemy import select
                        
                        # æŸ¥è¯¢ç¬”è®°æ˜¯å¦å­˜åœ¨
                        note_stmt = select(Note).where(
                            Note.id == chat_request.note_id,
                            Note.user_id == user_id,
                            Note.is_deleted == False
                        )
                        note_result = await db.execute(note_stmt)
                        note = note_result.scalar_one_or_none()
                        
                        # åˆ›å»ºèŠå¤©å¯¹è±¡å¹¶ä¼ é€’note_id
                        from backend.schemas.chat import ChatCreate
                        
                        # ä¸ä½¿ç”¨ç¬”è®°æ ‡é¢˜ï¼Œè®©ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆä¼šè¯æ ‡é¢˜
                        chat_data = ChatCreate(title="æ–°å¯¹è¯")
                        api_logger.info(f"ä»ç¬”è®°åˆ›å»ºæ–°ä¼šè¯ï¼Œä½¿ç”¨é»˜è®¤æ ‡é¢˜'æ–°å¯¹è¯'ï¼Œåç»­å°†è‡ªåŠ¨ç”Ÿæˆ")
                        
                        chat = await create_chat(db, user_id, chat_data=chat_data, agent_id=agent_id)
                        
                        # å¦‚æœåˆ›å»ºæˆåŠŸï¼Œå°†ä¼šè¯IDå…³è”åˆ°ç¬”è®°
                        if chat and chat_request.note_id and note:
                            # ğŸ” ä½¿ç”¨æ–°çš„å¤šå¯¹å¤šå…³è”æ–¹å¼
                            api_logger.info(f"ğŸ” å“åº”æœåŠ¡: å¼€å§‹å¤„ç†ç¬”è®°å…³è”: note_id={chat_request.note_id}, session_id={chat.public_id}")
                            
                            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä¸»è¦ä¼šè¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¾ä¸ºä¸»è¦ä¼šè¯
                            existing_primary = await note_session.get_primary_session_by_note(db, chat_request.note_id)
                            is_primary = existing_primary is None  # å¦‚æœæ²¡æœ‰ä¸»è¦ä¼šè¯ï¼Œè¿™ä¸ªå°±æ˜¯ä¸»è¦ä¼šè¯
                            
                            api_logger.info(f"ğŸ” å“åº”æœåŠ¡: ç°æœ‰ä¸»è¦ä¼šè¯: {existing_primary}, æ–°ä¼šè¯æ˜¯å¦ä¸ºä¸»è¦: {is_primary}")
                            
                            await note_session.create_note_session_link(
                                db, 
                                note_id=chat_request.note_id, 
                                session_id=chat.public_id,
                                is_primary=is_primary
                            )
                            
                            api_logger.info(f"ğŸ” å“åº”æœåŠ¡: ç¬”è®°ID {chat_request.note_id} å·²å…³è”åˆ°ä¼šè¯ID {chat.public_id}ï¼Œæ˜¯å¦ä¸ºä¸»è¦ä¼šè¯: {is_primary}")
                            
                            # éªŒè¯å…³è”æ˜¯å¦çœŸçš„è¢«åˆ›å»º
                            verification_sessions = await note_session.get_sessions_by_note(db, chat_request.note_id)
                            verification_session_ids = [s.public_id for s in verification_sessions]
                            api_logger.info(f"ğŸ” å“åº”æœåŠ¡: éªŒè¯ç¬”è®° {chat_request.note_id} å…³è”çš„ä¼šè¯åˆ—è¡¨: {verification_session_ids}")
                            
                            if chat.public_id in verification_session_ids:
                                api_logger.info(f"âœ… å“åº”æœåŠ¡: ç¬”è®° {chat_request.note_id} ä¸ä¼šè¯ {chat.public_id} å…³è”åˆ›å»ºæˆåŠŸ")
                            else:
                                api_logger.error(f"âŒ å“åº”æœåŠ¡: ç¬”è®° {chat_request.note_id} ä¸ä¼šè¯ {chat.public_id} å…³è”åˆ›å»ºå¤±è´¥ï¼")
                    else:
                        # å¸¸è§„åˆ›å»ºä¼šè¯
                        chat = await create_chat(db, user_id, agent_id=agent_id)
                        
                    session_id = chat.public_id
                    api_logger.info(f"åˆ›å»ºæ–°èŠå¤©ä¼šè¯: session_id={session_id}, user_id={user_id}, agent_id={agent_id}")
                else:
                    # éªŒè¯ä¼šè¯å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
                    chat = await get_chat(db, session_id)
                    if not chat or chat.user_id != user_id:
                        raise HTTPException(
                            status_code=status.HTTP_404_NOT_FOUND,
                            detail="èŠå¤©ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒè®¿é—®"
                        )
                    
                    # å¦‚æœå½“å‰ä¼šè¯æ²¡æœ‰å…³è”Agentï¼Œä½†è¯·æ±‚ä¸­æœ‰Agentï¼Œåˆ™æ›´æ–°ä¼šè¯
                    if agent_id and not chat.agent_id:
                        await update_chat_agent(db, session_id=session_id, agent_id=agent_id)
                        api_logger.info(f"æ›´æ–°ä¼šè¯çš„Agent: session_id={session_id}, agent_id={agent_id}")
                    
                    # å¦‚æœå½“å‰ä¼šè¯å·²å…³è”Agentï¼Œä½¿ç”¨è¯¥Agentçš„ä¿¡æ¯
                    elif chat.agent_id and not agent_id:
                        agent_id = chat.agent_id
                        current_agent = await agent_crud.get_agent_by_id(db, agent_id=agent_id)
                        if current_agent:
                            api_logger.info(f"ä»ä¼šè¯åŠ è½½Agent: AIåŠ©æ‰‹, ID={current_agent.public_id}")
            
            # è·å–ç”¨æˆ·å‘é€çš„å†…å®¹
            user_content = chat_request.content
            
            # å¤„ç†å›¾ç‰‡æ¶ˆæ¯ - æ„å»ºåŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯æ ¼å¼
            user_message_content = []
            
            # æ·»åŠ æ–‡æœ¬å†…å®¹
            if user_content and user_content.strip():
                user_message_content.append({
                    "type": "text",
                    "text": user_content
                })
            
            # æ·»åŠ å›¾ç‰‡å†…å®¹
            if hasattr(chat_request, 'images') and chat_request.images:
                for image in chat_request.images:
                    try:
                        # å°è¯•ä¸‹è½½å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64
                        async with aiohttp.ClientSession() as session:
                            async with session.get(image.url, timeout=aiohttp.ClientTimeout(total=10)) as response:
                                if response.status == 200:
                                    image_data = await response.read()
                                    # æ£€æµ‹å›¾ç‰‡æ ¼å¼
                                    content_type = response.headers.get('content-type', 'image/png')
                                    if 'image/' in content_type:
                                        image_format = content_type.split('/')[-1]
                                    else:
                                        image_format = 'png'  # é»˜è®¤æ ¼å¼
                                    
                                    # è½¬æ¢ä¸ºbase64
                                    base64_image = base64.b64encode(image_data).decode('utf-8')
                                    data_url = f"data:{content_type};base64,{base64_image}"
                                    
                                    user_message_content.append({
                                        "type": "image_url",
                                        "image_url": {
                                            "url": data_url,
                                            "detail": "high"  # ä½¿ç”¨é«˜ç»†èŠ‚æ¨¡å¼
                                        }
                                    })
                                    api_logger.info(f"æˆåŠŸè½¬æ¢å›¾ç‰‡ä¸ºbase64æ ¼å¼: {image.name}, å¤§å°: {len(image_data)} å­—èŠ‚")
                                else:
                                    api_logger.error(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status}, URL: {image.url}")
                                    # å¦‚æœä¸‹è½½å¤±è´¥ï¼Œä»ç„¶å°è¯•ä½¿ç”¨åŸURL
                                    user_message_content.append({
                                        "type": "image_url",
                                        "image_url": {
                                            "url": image.url,
                                            "detail": "high"
                                        }
                                    })
                    except Exception as download_error:
                        api_logger.error(f"ä¸‹è½½å›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(download_error)}, URL: {image.url}")
                        # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œå›é€€åˆ°åŸURL
                        user_message_content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": image.url,
                                "detail": "high"
                            }
                        })
                
                api_logger.info(f"ç”¨æˆ·æ¶ˆæ¯åŒ…å« {len(chat_request.images)} å¼ å›¾ç‰‡ï¼Œå·²å°è¯•è½¬æ¢ä¸ºbase64æ ¼å¼")
            
            # æ„å»ºæœ€ç»ˆçš„ç”¨æˆ·æ¶ˆæ¯
            if len(user_message_content) > 1:  # æœ‰å›¾ç‰‡æˆ–å¤šä¸ªå†…å®¹å…ƒç´ 
                final_user_message = user_message_content
                # ç”¨äºè®°å¿†å’Œæ•°æ®åº“çš„çº¯æ–‡æœ¬å†…å®¹
                content_for_memory = user_content
                if hasattr(chat_request, 'images') and chat_request.images:
                    image_info = f" [åŒ…å«{len(chat_request.images)}å¼ å›¾ç‰‡]"
                    content_for_memory = (user_content + image_info) if user_content else f"å‘é€äº†{len(chat_request.images)}å¼ å›¾ç‰‡"
            else:  # åªæœ‰æ–‡æœ¬
                final_user_message = user_content
                content_for_memory = user_content
            
            # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­ï¼ˆä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼‰
            memory_service.add_user_message(session_id, content_for_memory, user_id)
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ˆä¿å­˜å®Œæ•´çš„å›¾ç‰‡ä¿¡æ¯ï¼‰
            if db and user_id and session_id:
                # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯å†…å®¹ï¼ŒåŒ…å«å›¾ç‰‡ä¿¡æ¯
                if hasattr(chat_request, 'images') and chat_request.images:
                    # æ„å»ºåŒ…å«å›¾ç‰‡å’Œæ–‡æœ¬çš„å®Œæ•´æ¶ˆæ¯ç»“æ„
                    full_message_content = {
                        "type": "user_message",
                        "text_content": user_content,
                        "images": [
                            {
                                "url": image.url,
                                "name": image.name,
                                "size": image.size
                            } for image in chat_request.images
                        ]
                    }
                    # ä¿å­˜JSONæ ¼å¼çš„å®Œæ•´æ¶ˆæ¯
                    await add_message(
                        db=db,
                        session_id=session_id,
                        role="user",
                        content=json.dumps(full_message_content, ensure_ascii=False)
                    )
                    api_logger.info(f"ä¿å­˜åŒ…å«{len(chat_request.images)}å¼ å›¾ç‰‡çš„ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“")
                else:
                    # çº¯æ–‡æœ¬æ¶ˆæ¯ï¼Œç›´æ¥ä¿å­˜
                    await add_message(
                        db=db,
                        session_id=session_id,
                        role="user",
                        content=content_for_memory
                    )
            
            # ä»è®°å¿†æœåŠ¡è·å–å®Œæ•´çš„æ¶ˆæ¯è®°å½•
            messages = memory_service.get_messages(session_id)
            
            # å¦‚æœå½“å‰è¯·æ±‚åŒ…å«å›¾ç‰‡ï¼Œéœ€è¦æ›¿æ¢æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ä¸ºåŒ…å«å›¾ç‰‡çš„æ ¼å¼
            if hasattr(chat_request, 'images') and chat_request.images and len(user_message_content) > 1:
                api_logger.info(f"æ£€æµ‹åˆ°å›¾ç‰‡æ¶ˆæ¯ï¼Œå‡†å¤‡æ›¿æ¢æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯æ ¼å¼")
                
                # æ‰¾åˆ°æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å¹¶æ›¿æ¢ä¸ºåŒ…å«å›¾ç‰‡çš„æ ¼å¼
                for i in range(len(messages) - 1, -1, -1):
                    if messages[i].get("role") == "user":
                        api_logger.info(f"æ›¿æ¢ç”¨æˆ·æ¶ˆæ¯ç´¢å¼• {i}ï¼ŒåŸå†…å®¹: {str(messages[i]['content'])[:50]}...")
                        messages[i]["content"] = final_user_message
                        api_logger.info(f"æ›¿æ¢åçš„æ¶ˆæ¯æ ¼å¼: {json.dumps(final_user_message, ensure_ascii=False)[:200]}...")
                        break
                else:
                    api_logger.warning("æœªæ‰¾åˆ°ç”¨æˆ·æ¶ˆæ¯è¿›è¡Œå›¾ç‰‡æ ¼å¼æ›¿æ¢")
            else:
                api_logger.info("å½“å‰è¯·æ±‚ä¸åŒ…å«å›¾ç‰‡æˆ–å›¾ç‰‡æ•°æ®ä¸ºç©º")
                
            # è®°å½•æœ€ç»ˆå‘é€ç»™AIæ¨¡å‹çš„æ¶ˆæ¯æ ¼å¼
            if hasattr(chat_request, 'images') and chat_request.images:
                # å®‰å…¨åœ°è®°å½•æ¶ˆæ¯æ ¼å¼ï¼Œé¿å…è¿‡é•¿çš„æ—¥å¿—
                api_logger.info(f"å‡†å¤‡å‘é€ç»™AIæ¨¡å‹çš„æ¶ˆæ¯æ•°é‡: {len(messages)}")
                for idx, msg in enumerate(messages):
                    if msg.get("role") == "user" and isinstance(msg.get("content"), list):
                        api_logger.info(f"æ¶ˆæ¯ {idx} (ç”¨æˆ·): å¤æ‚æ ¼å¼ï¼ŒåŒ…å« {len(msg['content'])} ä¸ªå…ƒç´ ")
                        for elem_idx, elem in enumerate(msg["content"]):
                            if isinstance(elem, dict):
                                if elem.get("type") == "text":
                                    api_logger.info(f"  å…ƒç´  {elem_idx}: æ–‡æœ¬ - {elem.get('text', '')[:50]}...")
                                elif elem.get("type") == "image_url":
                                    api_logger.info(f"  å…ƒç´  {elem_idx}: å›¾ç‰‡ - URL: {elem.get('image_url', {}).get('url', 'unknown')}")
                    else:
                        content_preview = str(msg.get("content", ""))[:50]
                        api_logger.info(f"æ¶ˆæ¯ {idx} ({msg.get('role', 'unknown')}): {content_preview}...")
            
            # æ·»åŠ Agentçš„ç³»ç»Ÿæç¤ºè¯
            if current_agent and current_agent.system_prompt:
                # åœ¨æ¶ˆæ¯å¼€å¤´æ·»åŠ ç³»ç»Ÿæç¤º
                system_prompt = {"role": "system", "content": current_agent.system_prompt}
                messages.insert(0, system_prompt)
                api_logger.info(f"æ·»åŠ Agentç³»ç»Ÿæç¤ºè¯: {current_agent.system_prompt[:30]}...")
            
            api_logger.debug(f"è¯·æ±‚æ¶ˆæ¯: {json.dumps(messages, ensure_ascii=False)}")
            
            # å¦‚æœæœ‰Agentï¼Œä½¿ç”¨Agentçš„è®¾ç½®
            if current_agent:
                # ç¡®ä¿ç”¨æˆ·çš„MCPæœåŠ¡å™¨å·²åŠ è½½ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                try:
                    from backend.services.mcp_service import mcp_service
                    if user_id and mcp_service.is_enabled():
                        await mcp_service.ensure_user_servers_loaded(user_id)
                        api_logger.info(f"å·²ä¸ºç”¨æˆ· {user_id} åŠ è½½MCPæœåŠ¡å™¨")
                except Exception as e:
                    api_logger.warning(f"åŠ è½½ç”¨æˆ·MCPæœåŠ¡å™¨å¤±è´¥: {e}")
                
                # ä¼˜å…ˆä½¿ç”¨è¯·æ±‚ä¸­çš„æ¨¡å‹ï¼Œå¦‚æœæ²¡æœ‰æä¾›åˆ™ä½¿ç”¨Agentçš„é»˜è®¤æ¨¡å‹
                if chat_request.model:
                    use_model = chat_request.model
                    api_logger.info(f"ä½¿ç”¨è¯·æ±‚ä¸­æŒ‡å®šçš„æ¨¡å‹: {use_model}")
                else:
                    # å…ˆå¤‡ä»½ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼Œä»¥é˜²æŒ‡å®šæ¨¡å‹ä¸å¯ç”¨
                    agent_model = current_agent.model
                    use_model = agent_model if agent_model else openai_client_service.model
                    api_logger.info(f"ä½¿ç”¨Agenté»˜è®¤æ¨¡å‹: {use_model}")
                
                # å¦‚æœAgentæœ‰æ¨¡å‹è®¾ç½®ï¼Œä½¿ç”¨Agentçš„æ¨¡å‹è®¾ç½®
                if current_agent.model_settings:
                    model_settings = current_agent.model_settings
                    # ç¡®ä¿model_settingsæ˜¯å­—å…¸
                    if not isinstance(model_settings, dict) and hasattr(model_settings, "dict"):
                        model_settings = model_settings.dict()
                    elif not isinstance(model_settings, dict):
                        model_settings = {}
                    
                    if "temperature" in model_settings:
                        temperature = model_settings["temperature"]
                    if "top_p" in model_settings:
                        top_p = model_settings["top_p"]
                    if "max_tokens" in model_settings:
                        max_tokens = model_settings["max_tokens"]
                
                api_logger.info(f"ä½¿ç”¨Agentæ¨¡å‹è®¾ç½®: model={use_model}, temperature={temperature}, top_p={top_p}, max_tokens={max_tokens}")
            elif chat_request.model:
                # å¦‚æœæ²¡æœ‰Agentä½†è¯·æ±‚ä¸­æŒ‡å®šäº†æ¨¡å‹ï¼Œä½¿ç”¨è¯·æ±‚ä¸­çš„æ¨¡å‹
                use_model = chat_request.model
                api_logger.info(f"æ²¡æœ‰Agentï¼Œä½¿ç”¨è¯·æ±‚ä¸­æŒ‡å®šçš„æ¨¡å‹: {use_model}")
            else:
                # éƒ½æ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
                api_logger.info(f"ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ¨¡å‹: {use_model}")
            
            # è·å–å·¥å…·é…ç½®
            tools = await chat_tool_handler.get_agent_tools_async(current_agent, user_id, db) if current_agent else []
            has_tools = len(tools) > 0
            api_logger.info(f"å½“å‰èŠå¤©å¯ç”¨å·¥å…·: {has_tools}, å·¥å…·æ•°é‡: {len(tools)}")
            
            # è°ƒç”¨API - å°è¯•ç›´æ¥ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯
            try:
                api_logger.info(f"ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯è°ƒç”¨API - URL: {openai_client_service.async_client.base_url}")
                
                # å‡†å¤‡APIè°ƒç”¨å‚æ•°
                api_params = {
                    "model": use_model,
                    "messages": messages,
                    "max_tokens": max_tokens,
                    "temperature": temperature,
                    "top_p": top_p,
                    "stream": False
                }
                
                # å¦‚æœæœ‰å·¥å…·ï¼Œæ·»åŠ å·¥å…·é…ç½®
                if has_tools:
                    api_params["tools"] = tools
                
                # è®°å½•è¯·æ±‚å‚æ•°è¯¦æƒ…
                api_logger.info(f"[å¤§æ¨¡å‹è¯·æ±‚] APIè°ƒç”¨å‚æ•°è¯¦æƒ…: model={use_model}, max_tokens={max_tokens}, temperature={temperature}, æ¶ˆæ¯æ•°é‡={len(messages)}, å¯ç”¨å·¥å…·={has_tools}")
                
                # è°ƒç”¨API
                response = await openai_client_service.async_client.chat.completions.create(**api_params)
                
                api_logger.info(f"[å¤§æ¨¡å‹å“åº”] APIå“åº”ç±»å‹: {type(response)}")
                
                # æ£€æŸ¥å“åº”ç±»å‹
                if isinstance(response, str):
                    api_logger.error(f"APIè¿”å›äº†å­—ç¬¦ä¸²è€Œä¸æ˜¯å¯¹è±¡: {response}")
                    raise ValueError(f"APIè¿”å›äº†é”™è¯¯æ ¼å¼: {response}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
                assistant_message = response.choices[0].message
                tool_calls = assistant_message.tool_calls if hasattr(assistant_message, 'tool_calls') else None
                
                # åˆå§‹åŒ–äº¤äº’æµç¨‹è®°å½•
                interaction_flow = []
                
                # å¦‚æœæœ‰å·¥å…·è°ƒç”¨
                if tool_calls:
                    api_logger.info(f"æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨è¯·æ±‚: {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                    
                    # å…ˆä¿å­˜AIæ¶ˆæ¯ï¼ˆä¸åŒ…å«å·¥å…·è°ƒç”¨æ•°æ®ï¼‰
                    ai_message = None
                    if db and user_id and session_id:
                        ai_message = await add_message(
                            db=db,
                            session_id=session_id,
                            role="assistant",
                            content=assistant_message.content or "",
                            agent_id=agent_id
                        )
                    
                    # ä½¿ç”¨æ–°çš„äº¤äº’æµç¨‹å¤„ç†æ–¹æ³•
                    final_assistant_content = await ChatResponseService._process_tool_calls_with_interaction_flow_non_stream(
                        assistant_message.content or "",
                        tool_calls,
                        messages,
                        current_agent,
                        use_model,
                        max_tokens,
                        temperature,
                        top_p,
                        tools,
                        has_tools,
                        session_id,
                        db,
                        ai_message.public_id if ai_message else None,
                        interaction_flow,
                        user_id
                    )
                    
                    # ä¼°ç®—tokenä½¿ç”¨é‡ï¼ˆå› ä¸ºé€’å½’è°ƒç”¨å¯èƒ½æ— æ³•å‡†ç¡®è·å–ï¼‰
                    estimated_tokens = len(final_assistant_content) // 4
                    estimated_prompt_tokens = len(str(messages)) // 4
                    estimated_total_tokens = estimated_tokens + estimated_prompt_tokens
                    
                    # æ„å»ºæœ€ç»ˆçš„JSONç»“æ„
                    final_json_content = {
                        "type": "agent_response",
                        "interaction_flow": interaction_flow
                    }
                    
                    # å°†æœ€ç»ˆçš„åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­ï¼ˆä½¿ç”¨çº¯æ–‡æœ¬ï¼‰
                    memory_service.add_assistant_message(session_id, final_assistant_content, user_id)
                    
                    # æ›´æ–°AIæ¶ˆæ¯çš„å†…å®¹ä¸ºJSONç»“æ„
                    if ai_message:
                        ai_message.content = json.dumps(final_json_content, ensure_ascii=False)
                        ai_message.tokens = estimated_tokens
                        ai_message.prompt_tokens = estimated_prompt_tokens
                        ai_message.total_tokens = estimated_total_tokens
                        await db.commit()
                        await db.refresh(ai_message)
                    
                    api_logger.info(f"é€’å½’å·¥å…·è°ƒç”¨å®Œæˆï¼Œæœ€ç»ˆå“åº”é•¿åº¦: {len(final_assistant_content)}")
                    
                    # ä½¿ç”¨æœ€ç»ˆå†…å®¹å’Œä¼°ç®—çš„tokenæ•°é‡
                    assistant_content = final_assistant_content
                    token_usage_dict = {
                        "prompt_tokens": estimated_prompt_tokens,
                        "completion_tokens": estimated_tokens,
                        "total_tokens": estimated_total_tokens
                    }
                else:
                    # å¸¸è§„å“åº”å¤„ç†ï¼ˆæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼‰
                    token_usage = response.usage
                    assistant_content = assistant_message.content
                    
                    # å¦‚æœæœ‰å†…å®¹ï¼Œè®°å½•åˆ°äº¤äº’æµç¨‹
                    if assistant_content and assistant_content.strip():
                        interaction_flow.append({
                            "type": "text",
                            "content": assistant_content,
                            "timestamp": datetime.now().isoformat()
                        })
                    
                    # æ„å»ºJSONç»“æ„
                    final_json_content = {
                        "type": "agent_response",
                        "interaction_flow": interaction_flow
                    }
                    
                    # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­ï¼ˆä½¿ç”¨çº¯æ–‡æœ¬ï¼‰
                    memory_service.add_assistant_message(session_id, assistant_content, user_id)
                    
                    # å¦‚æœæä¾›äº†æ•°æ®åº“ä¼šè¯ï¼Œä¿å­˜AIå›å¤ï¼ˆä½¿ç”¨JSONç»“æ„ï¼‰
                    if db and user_id and session_id:
                        await add_message(
                            db=db,
                            session_id=session_id,
                            role="assistant",
                            content=json.dumps(final_json_content, ensure_ascii=False),
                            tokens=token_usage.completion_tokens,
                            prompt_tokens=token_usage.prompt_tokens,
                            total_tokens=token_usage.total_tokens,
                            agent_id=agent_id
                        )
                    
                    api_logger.info(f"OpenAI APIè°ƒç”¨æˆåŠŸ, ç”Ÿæˆæ–‡æœ¬é•¿åº¦: {len(assistant_content)}")
                    
                    # è®¾ç½®tokenä½¿ç”¨é‡å­—å…¸
                    token_usage_dict = {
                        "prompt_tokens": token_usage.prompt_tokens,
                        "completion_tokens": token_usage.completion_tokens,
                        "total_tokens": token_usage.total_tokens
                    }
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜
                if db and session_id and user_content:
                    await chat_session_manager.auto_generate_title_if_needed(db, session_id, user_content)
                
                return ChatCompletionResponse(
                    message=Message(
                        content=assistant_content
                    ),
                    usage=token_usage_dict,
                    session_id=session_id
                )
            except Exception as api_error:
                api_logger.error(f"OpenAI APIè°ƒç”¨å‡ºé”™: {str(api_error)}", exc_info=True)
                
                # å¦‚æœæ˜¯å› ä¸ºæ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹
                if "æ— å¯ç”¨æ¸ é“" in str(api_error) and current_agent and use_model != openai_client_service.model:
                    api_logger.info(f"å°è¯•ä½¿ç”¨é»˜è®¤æ¨¡å‹ {openai_client_service.model} é‡æ–°è¯·æ±‚")
                    try:
                        response = await openai_client_service.async_client.chat.completions.create(
                            model=openai_client_service.model,
                            messages=messages,
                            max_tokens=max_tokens,
                            temperature=temperature,
                            top_p=top_p,
                            stream=False
                        )
                        
                        # æå–å¹¶è¿”å›å“åº”
                        assistant_message = response.choices[0].message
                        token_usage = response.usage
                        assistant_content = assistant_message.content
                        
                        # å°†åŠ©æ‰‹æ¶ˆæ¯æ·»åŠ åˆ°è®°å¿†ä¸­
                        memory_service.add_assistant_message(session_id, assistant_content, user_id)
                        
                        api_logger.info(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹ {openai_client_service.model} æˆåŠŸ, ç”Ÿæˆæ–‡æœ¬é•¿åº¦: {len(assistant_content)}")
                        
                        # å¦‚æœæä¾›äº†æ•°æ®åº“ä¼šè¯ï¼Œä¿å­˜AIå›å¤
                        if db and user_id and session_id:
                            await add_message(
                                db=db,
                                session_id=session_id,
                                role="assistant",
                                content=assistant_content,
                                tokens=token_usage.completion_tokens,
                                prompt_tokens=token_usage.prompt_tokens,
                                total_tokens=token_usage.total_tokens,
                                agent_id=agent_id
                            )
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜
                        if db and session_id and user_content:
                            await chat_session_manager.auto_generate_title_if_needed(db, session_id, user_content)
                        
                        return ChatCompletionResponse(
                            message=Message(
                                content=assistant_content
                            ),
                            usage={
                                "prompt_tokens": token_usage.prompt_tokens,
                                "completion_tokens": token_usage.completion_tokens,
                                "total_tokens": token_usage.total_tokens
                            },
                            session_id=session_id
                        )
                    except Exception as fallback_error:
                        api_logger.error(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹ {openai_client_service.model} ä»ç„¶å¤±è´¥: {str(fallback_error)}", exc_info=True)
                
                # åˆ›å»ºä¸€ä¸ªç®€å•çš„å“åº”ï¼Œé¿å…è¿›ä¸€æ­¥çš„é”™è¯¯
                error_message = f"AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(api_error)}"
                
                if db and user_id and session_id:
                    await add_message(
                        db=db,
                        session_id=session_id,
                        role="assistant",
                        content=error_message
                    )
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜
                if db and session_id and user_content:
                    await chat_session_manager.auto_generate_title_if_needed(db, session_id, user_content)
                
                return ChatCompletionResponse(
                    message=Message(
                        content=error_message
                    ),
                    usage={
                        "prompt_tokens": len(str(messages)),
                        "completion_tokens": len(error_message),
                        "total_tokens": len(str(messages)) + len(error_message)
                    },
                    session_id=session_id
                )
                
        except Exception as e:
            api_logger.error(f"OpenAI APIè°ƒç”¨å¤±è´¥: {str(e)}", exc_info=True)
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„å“åº”ï¼Œé¿å…è¿›ä¸€æ­¥çš„é”™è¯¯
            error_message = f"AIæœåŠ¡å‘ç”Ÿé”™è¯¯: {str(e)}"
            
            if db and user_id and session_id:
                try:
                    await add_message(
                        db=db,
                        session_id=session_id,
                        role="assistant",
                        content=error_message
                    )
                except Exception as db_error:
                    api_logger.error(f"ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°æ•°æ®åº“å¤±è´¥: {str(db_error)}")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜
            if db and session_id and user_content:
                await chat_session_manager.auto_generate_title_if_needed(db, session_id, user_content)
            
            return ChatCompletionResponse(
                message=Message(
                    content=error_message
                ),
                usage={
                    "prompt_tokens": 0,
                    "completion_tokens": 0,
                    "total_tokens": 0
                },
                session_id=session_id
            )


# åˆ›å»ºå…¨å±€èŠå¤©å“åº”æœåŠ¡å®ä¾‹
chat_response_service = ChatResponseService() 